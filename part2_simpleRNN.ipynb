{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = dataset['train'] \n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Model Training & Evaluation - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.5.2 threadpoolctl-3.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embedding matrix with shape: (16633, 300)\n",
      "Vocabulary size (word_to_index): 16633\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "import random\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the embedding matrix and word_to_index from the pickle file\n",
    "with open(\"base_embedding_matrix.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    embedding_matrix = data[\"embeddings\"]\n",
    "    word_to_index = data[\"word_to_index\"]\n",
    "\n",
    "# Convert embedding_matrix to a NumPy array and a PyTorch tensor\n",
    "embedding_matrix_array = np.array(embedding_matrix)\n",
    "embedding_matrix_tensor = torch.tensor(embedding_matrix_array, dtype=torch.float32)\n",
    "\n",
    "print(f\"Loaded embedding matrix with shape: {embedding_matrix_array.shape}\")\n",
    "print(f\"Vocabulary size (word_to_index): {len(word_to_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures reproducibility in CUDA operations\n",
    "    torch.backends.cudnn.benchmark = False     # Disables some optimizations to ensure determinism\n",
    "\n",
    "# Set the seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tokenized_train_texts = []\n",
    "for sentence in train_dataset['text']:\n",
    "    # Tokenize the sentence using spaCy and store tokens as a list of strings\n",
    "    tokens = [token.text for token in nlp(sentence.lower())]\n",
    "    pre_tokenized_train_texts.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-tokenize validation and test sets\n",
    "pre_tokenized_validation_texts = [[token.text for token in nlp(sentence.lower())] for sentence in validation_dataset['text']]\n",
    "pre_tokenized_test_texts = [[token.text for token in nlp(sentence.lower())] for sentence in test_dataset['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset for PyTorch\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, tokenized_texts, labels, vocab, embedding_matrix, max_len=30):\n",
    "        self.texts = tokenized_texts\n",
    "        self.labels = labels\n",
    "        self.vocab = word_to_index\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        vectorized_text = self.vectorize(tokens)\n",
    "        return torch.tensor(vectorized_text), torch.tensor(label)\n",
    "\n",
    "    def vectorize(self, tokens):\n",
    "        vectorized = [self.vocab.get(token, self.vocab['<UNK>']) for token in tokens]\n",
    "\n",
    "        # Check for out-of-range indices\n",
    "        for index in vectorized:\n",
    "            if index >= len(self.embedding_matrix):\n",
    "                raise ValueError(f\"Index {index} is out of range for the embedding matrix.\")\n",
    "                \n",
    "        # Pad or truncate to max_len\n",
    "        if len(vectorized) < self.max_len:\n",
    "            vectorized += [self.vocab['<PAD>']] * (self.max_len - len(vectorized))\n",
    "        else:\n",
    "            vectorized = vectorized[:self.max_len]\n",
    "        return vectorized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RNN Model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_size, output_size, num_layers=2, bidirectional=False):\n",
    "        super(RNNModel, self).__init__()\n",
    "        vocab_size, embedding_dim = embedding_matrix.shape\n",
    "        \n",
    "        # Define the embedding layer with pretrained embeddings, frozen\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32), freeze=True)\n",
    "        \n",
    "        # Define RNN layer \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x)\n",
    "        # Using Average Pooling\n",
    "        out = torch.mean(out, dim=1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DataLoader\n",
    "def create_data_loader(dataset, batch_size):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_dataset_instance = SentimentDataset(pre_tokenized_train_texts, train_dataset['label'], word_to_index, embedding_matrix)\n",
    "val_dataset_instance = SentimentDataset(pre_tokenized_validation_texts, validation_dataset['label'], word_to_index, embedding_matrix)\n",
    "test_dataset_instance = SentimentDataset(pre_tokenized_test_texts, test_dataset['label'], word_to_index, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, labels in data_loader:\n",
    "            output = model.forward(data)\n",
    "            probs = torch.sigmoid(output)  # Apply sigmoid to get probabilities\n",
    "            predicted = (probs >= 0.5).long()  # Convert probabilities to binary predictions\n",
    "            all_preds.extend(predicted.cpu().numpy().flatten().tolist())\n",
    "            all_labels.extend(labels.cpu().numpy().tolist())\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate function\n",
    "def train_and_validate(model, train_loader, val_loader, optimizer, criterion, max_epochs=100, convergence_threshold=0.001):\n",
    "    best_val_acc = 0\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = criterion(output, target.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        print(f\"Epoch {epoch+1}/{max_epochs}, Loss: {running_loss/len(train_loader)}, Val Accuracy: {val_acc}\")\n",
    "        \n",
    "        # Check for improvement\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            epochs_without_improvement = 0  # Reset counter\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            \n",
    "        # Check for convergence\n",
    "        if epochs_without_improvement >= 10:  # Convergence condition (no improvement for 5 epochs)\n",
    "            print(\"Convergence reached, stopping training.\")\n",
    "            break\n",
    "            \n",
    "    return best_val_acc, epoch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with the following hyperparameters:\n",
      "Learning Rate: 0.001, Batch Size: 32, Hidden Size: 128, Optimizer: adam\n",
      "Epoch 1/100, Loss: 0.5837534061085419, Val Accuracy: 0.7213883677298312\n",
      "Epoch 2/100, Loss: 0.5237110727065512, Val Accuracy: 0.6894934333958724\n",
      "Epoch 3/100, Loss: 0.5254920146215275, Val Accuracy: 0.7307692307692307\n",
      "Epoch 4/100, Loss: 0.5011564123719819, Val Accuracy: 0.7373358348968105\n",
      "Epoch 5/100, Loss: 0.48441201649355087, Val Accuracy: 0.7504690431519699\n",
      "Epoch 6/100, Loss: 0.4728004155534037, Val Accuracy: 0.7514071294559099\n",
      "Epoch 7/100, Loss: 0.46884569704309387, Val Accuracy: 0.7532833020637899\n",
      "Epoch 8/100, Loss: 0.44855630604292124, Val Accuracy: 0.7410881801125704\n",
      "Epoch 9/100, Loss: 0.4370223778798786, Val Accuracy: 0.7607879924953096\n",
      "Epoch 10/100, Loss: 0.4207631019728907, Val Accuracy: 0.7626641651031895\n",
      "Epoch 11/100, Loss: 0.40114425345976257, Val Accuracy: 0.7429643527204502\n",
      "Epoch 12/100, Loss: 0.38232182931810726, Val Accuracy: 0.7448405253283302\n",
      "Epoch 13/100, Loss: 0.3488808201995682, Val Accuracy: 0.7532833020637899\n",
      "Epoch 14/100, Loss: 0.30867630522349354, Val Accuracy: 0.7532833020637899\n",
      "Epoch 15/100, Loss: 0.2876500610945823, Val Accuracy: 0.7523452157598499\n",
      "Epoch 16/100, Loss: 0.25603020297230855, Val Accuracy: 0.7420262664165104\n",
      "Epoch 17/100, Loss: 0.22494849312897033, Val Accuracy: 0.7467166979362101\n",
      "Epoch 18/100, Loss: 0.19574560393833937, Val Accuracy: 0.7354596622889306\n",
      "Epoch 19/100, Loss: 0.1524915119305197, Val Accuracy: 0.7298311444652908\n",
      "Epoch 20/100, Loss: 0.13146637833576078, Val Accuracy: 0.7317073170731707\n",
      "Convergence reached, stopping training.\n",
      "Learning Rate: 0.001, Batch Size: 32 Optimizer: adam, Validation Accuracy: 0.7626641651031895\n",
      "Training with the following hyperparameters:\n",
      "Learning Rate: 0.001, Batch Size: 32, Hidden Size: 128, Optimizer: sgd\n",
      "Epoch 1/100, Loss: 0.693726573767287, Val Accuracy: 0.49343339587242024\n",
      "Epoch 2/100, Loss: 0.6933798211790649, Val Accuracy: 0.4915572232645403\n",
      "Epoch 3/100, Loss: 0.6931114299466994, Val Accuracy: 0.49530956848030017\n",
      "Epoch 4/100, Loss: 0.6928575637188743, Val Accuracy: 0.49530956848030017\n",
      "Epoch 5/100, Loss: 0.6926335576321748, Val Accuracy: 0.5046904315196998\n",
      "Epoch 6/100, Loss: 0.6924158892827981, Val Accuracy: 0.5121951219512195\n",
      "Epoch 7/100, Loss: 0.6921870395931858, Val Accuracy: 0.5234521575984991\n",
      "Epoch 8/100, Loss: 0.691978106561225, Val Accuracy: 0.5272045028142589\n",
      "Epoch 9/100, Loss: 0.6917629016472606, Val Accuracy: 0.5431519699812383\n",
      "Epoch 10/100, Loss: 0.6915483378738946, Val Accuracy: 0.5525328330206379\n",
      "Epoch 11/100, Loss: 0.6913214788008272, Val Accuracy: 0.5572232645403377\n",
      "Epoch 12/100, Loss: 0.6911037345504046, Val Accuracy: 0.5694183864915572\n",
      "Epoch 13/100, Loss: 0.6908684067065349, Val Accuracy: 0.5797373358348968\n",
      "Epoch 14/100, Loss: 0.6906491812695278, Val Accuracy: 0.5797373358348968\n",
      "Epoch 15/100, Loss: 0.6904030562786574, Val Accuracy: 0.5863039399624765\n",
      "Epoch 16/100, Loss: 0.6901565354861571, Val Accuracy: 0.5853658536585366\n",
      "Epoch 17/100, Loss: 0.6899026627844193, Val Accuracy: 0.5919324577861164\n",
      "Epoch 18/100, Loss: 0.6896667710404271, Val Accuracy: 0.5853658536585366\n",
      "Epoch 19/100, Loss: 0.6893858369370078, Val Accuracy: 0.5881801125703565\n",
      "Epoch 20/100, Loss: 0.6891284687688735, Val Accuracy: 0.5956848030018762\n",
      "Epoch 21/100, Loss: 0.6888303678580437, Val Accuracy: 0.6041275797373359\n",
      "Epoch 22/100, Loss: 0.6885413051990981, Val Accuracy: 0.6106941838649156\n",
      "Epoch 23/100, Loss: 0.6882344557997886, Val Accuracy: 0.6144465290806754\n",
      "Epoch 24/100, Loss: 0.6878988436991802, Val Accuracy: 0.6116322701688556\n",
      "Epoch 25/100, Loss: 0.6875692282276653, Val Accuracy: 0.6153846153846154\n",
      "Epoch 26/100, Loss: 0.687231028571111, Val Accuracy: 0.6125703564727955\n",
      "Epoch 27/100, Loss: 0.6868499733982015, Val Accuracy: 0.6153846153846154\n",
      "Epoch 28/100, Loss: 0.6864592421813851, Val Accuracy: 0.6172607879924953\n",
      "Epoch 29/100, Loss: 0.6860439395636655, Val Accuracy: 0.6125703564727955\n",
      "Epoch 30/100, Loss: 0.6855906690104624, Val Accuracy: 0.6200750469043153\n",
      "Epoch 31/100, Loss: 0.6851309685224898, Val Accuracy: 0.6200750469043153\n",
      "Epoch 32/100, Loss: 0.6846296780564812, Val Accuracy: 0.6200750469043153\n",
      "Epoch 33/100, Loss: 0.6841095107771484, Val Accuracy: 0.6210131332082551\n",
      "Epoch 34/100, Loss: 0.683507926901628, Val Accuracy: 0.6238273921200751\n",
      "Epoch 35/100, Loss: 0.6829348277956359, Val Accuracy: 0.626641651031895\n",
      "Epoch 36/100, Loss: 0.6822002021114478, Val Accuracy: 0.6210131332082551\n",
      "Epoch 37/100, Loss: 0.6814897640814049, Val Accuracy: 0.6303939962476548\n",
      "Epoch 38/100, Loss: 0.6806932955645444, Val Accuracy: 0.6322701688555347\n",
      "Epoch 39/100, Loss: 0.6797992386175006, Val Accuracy: 0.6285178236397748\n",
      "Epoch 40/100, Loss: 0.6788113820418883, Val Accuracy: 0.6313320825515948\n",
      "Epoch 41/100, Loss: 0.6777421401234601, Val Accuracy: 0.6350844277673546\n",
      "Epoch 42/100, Loss: 0.6764761374684308, Val Accuracy: 0.6303939962476548\n",
      "Epoch 43/100, Loss: 0.6751431454433484, Val Accuracy: 0.6322701688555347\n",
      "Epoch 44/100, Loss: 0.6735641835780626, Val Accuracy: 0.6341463414634146\n",
      "Epoch 45/100, Loss: 0.6717879680658547, Val Accuracy: 0.6378986866791745\n",
      "Epoch 46/100, Loss: 0.6697617012463258, Val Accuracy: 0.6388367729831145\n",
      "Epoch 47/100, Loss: 0.6673341272922044, Val Accuracy: 0.6444652908067542\n",
      "Epoch 48/100, Loss: 0.6643470356080416, Val Accuracy: 0.6397748592870544\n",
      "Epoch 49/100, Loss: 0.6610375236482656, Val Accuracy: 0.6538461538461539\n",
      "Epoch 50/100, Loss: 0.6567040407255794, Val Accuracy: 0.6425891181988743\n",
      "Epoch 51/100, Loss: 0.6515046266580788, Val Accuracy: 0.6575984990619137\n",
      "Epoch 52/100, Loss: 0.6449637104955952, Val Accuracy: 0.6660412757973734\n",
      "Epoch 53/100, Loss: 0.6366848383056983, Val Accuracy: 0.6622889305816135\n",
      "Epoch 54/100, Loss: 0.6267038621706016, Val Accuracy: 0.6716697936210131\n",
      "Epoch 55/100, Loss: 0.615012490905626, Val Accuracy: 0.6688555347091932\n",
      "Epoch 56/100, Loss: 0.6041006292966421, Val Accuracy: 0.6707317073170732\n",
      "Epoch 57/100, Loss: 0.5945146938834744, Val Accuracy: 0.6819887429643527\n",
      "Epoch 58/100, Loss: 0.5848042280709699, Val Accuracy: 0.6801125703564728\n",
      "Epoch 59/100, Loss: 0.5765816984551676, Val Accuracy: 0.6857410881801126\n",
      "Epoch 60/100, Loss: 0.5692321857932802, Val Accuracy: 0.698874296435272\n",
      "Epoch 61/100, Loss: 0.5624996798761775, Val Accuracy: 0.7063789868667918\n",
      "Epoch 62/100, Loss: 0.5568510531709435, Val Accuracy: 0.7054409005628518\n",
      "Epoch 63/100, Loss: 0.5512421698159493, Val Accuracy: 0.7138836772983115\n",
      "Epoch 64/100, Loss: 0.5466228381971295, Val Accuracy: 0.7045028142589118\n",
      "Epoch 65/100, Loss: 0.5431630567888196, Val Accuracy: 0.7157598499061913\n",
      "Epoch 66/100, Loss: 0.5393766665949804, Val Accuracy: 0.7157598499061913\n",
      "Epoch 67/100, Loss: 0.5364465921112661, Val Accuracy: 0.7166979362101313\n",
      "Epoch 68/100, Loss: 0.5343591902363166, Val Accuracy: 0.7166979362101313\n",
      "Epoch 69/100, Loss: 0.5306349268343564, Val Accuracy: 0.7195121951219512\n",
      "Epoch 70/100, Loss: 0.5288157525580474, Val Accuracy: 0.7110694183864915\n",
      "Epoch 71/100, Loss: 0.5267621378103892, Val Accuracy: 0.7185741088180112\n",
      "Epoch 72/100, Loss: 0.5233217560396659, Val Accuracy: 0.725140712945591\n",
      "Epoch 73/100, Loss: 0.5209120078368134, Val Accuracy: 0.7157598499061913\n",
      "Epoch 74/100, Loss: 0.5200882184594758, Val Accuracy: 0.7223264540337712\n",
      "Epoch 75/100, Loss: 0.517936187736997, Val Accuracy: 0.726078799249531\n",
      "Epoch 76/100, Loss: 0.5153734007578218, Val Accuracy: 0.7166979362101313\n",
      "Epoch 77/100, Loss: 0.5135243086332686, Val Accuracy: 0.7223264540337712\n",
      "Epoch 78/100, Loss: 0.5122544641575116, Val Accuracy: 0.7185741088180112\n",
      "Epoch 79/100, Loss: 0.5110632401057397, Val Accuracy: 0.7195121951219512\n",
      "Epoch 80/100, Loss: 0.509869993514336, Val Accuracy: 0.7223264540337712\n",
      "Epoch 81/100, Loss: 0.5082573763440165, Val Accuracy: 0.7270168855534709\n",
      "Epoch 82/100, Loss: 0.5066403425141667, Val Accuracy: 0.724202626641651\n",
      "Epoch 83/100, Loss: 0.5070342908191324, Val Accuracy: 0.724202626641651\n",
      "Epoch 84/100, Loss: 0.5047696818796437, Val Accuracy: 0.7138836772983115\n",
      "Epoch 85/100, Loss: 0.5021541497010863, Val Accuracy: 0.7279549718574109\n",
      "Epoch 86/100, Loss: 0.5013821993427776, Val Accuracy: 0.7185741088180112\n",
      "Epoch 87/100, Loss: 0.5023301126581899, Val Accuracy: 0.724202626641651\n",
      "Epoch 88/100, Loss: 0.5019465055358544, Val Accuracy: 0.7335834896810507\n",
      "Epoch 89/100, Loss: 0.49954958879545835, Val Accuracy: 0.724202626641651\n",
      "Epoch 90/100, Loss: 0.5000979276408863, Val Accuracy: 0.723264540337711\n",
      "Epoch 91/100, Loss: 0.4981257575616408, Val Accuracy: 0.7317073170731707\n",
      "Epoch 92/100, Loss: 0.49677864877918687, Val Accuracy: 0.7345215759849906\n",
      "Epoch 93/100, Loss: 0.4955946400147699, Val Accuracy: 0.7307692307692307\n",
      "Epoch 94/100, Loss: 0.49602174814720723, Val Accuracy: 0.7326454033771107\n",
      "Epoch 95/100, Loss: 0.4964833070946097, Val Accuracy: 0.7288930581613509\n",
      "Epoch 96/100, Loss: 0.49505055441838525, Val Accuracy: 0.7129455909943715\n",
      "Epoch 97/100, Loss: 0.49347421984547535, Val Accuracy: 0.7317073170731707\n",
      "Epoch 98/100, Loss: 0.4919158687975523, Val Accuracy: 0.724202626641651\n",
      "Epoch 99/100, Loss: 0.4925900125101711, Val Accuracy: 0.7363977485928705\n",
      "Epoch 100/100, Loss: 0.4915213379520602, Val Accuracy: 0.7317073170731707\n",
      "Learning Rate: 0.001, Batch Size: 32 Optimizer: sgd, Validation Accuracy: 0.7363977485928705\n",
      "Training with the following hyperparameters:\n",
      "Learning Rate: 0.001, Batch Size: 32, Hidden Size: 128, Optimizer: rmsprop\n",
      "Epoch 1/100, Loss: 0.6006116451842062, Val Accuracy: 0.7185741088180112\n",
      "Epoch 2/100, Loss: 0.5291635987910439, Val Accuracy: 0.723264540337711\n",
      "Epoch 3/100, Loss: 0.5092754378524166, Val Accuracy: 0.7363977485928705\n",
      "Epoch 4/100, Loss: 0.49793790531962107, Val Accuracy: 0.7213883677298312\n",
      "Epoch 5/100, Loss: 0.487939700874943, Val Accuracy: 0.7392120075046904\n",
      "Epoch 6/100, Loss: 0.48416264695621164, Val Accuracy: 0.7439024390243902\n",
      "Epoch 7/100, Loss: 0.472534345944276, Val Accuracy: 0.726078799249531\n",
      "Epoch 8/100, Loss: 0.46594922562663477, Val Accuracy: 0.7307692307692307\n",
      "Epoch 9/100, Loss: 0.4577666035528933, Val Accuracy: 0.7570356472795498\n",
      "Epoch 10/100, Loss: 0.4489727159787653, Val Accuracy: 0.7514071294559099\n",
      "Epoch 11/100, Loss: 0.437297441260645, Val Accuracy: 0.7223264540337712\n",
      "Epoch 12/100, Loss: 0.428609714079439, Val Accuracy: 0.7514071294559099\n",
      "Epoch 13/100, Loss: 0.4243670686353905, Val Accuracy: 0.7542213883677298\n",
      "Epoch 14/100, Loss: 0.409946401746532, Val Accuracy: 0.7392120075046904\n",
      "Epoch 15/100, Loss: 0.4202194586675265, Val Accuracy: 0.7467166979362101\n",
      "Epoch 16/100, Loss: 0.4108982369136275, Val Accuracy: 0.7457786116322702\n",
      "Epoch 17/100, Loss: 0.399074337567283, Val Accuracy: 0.7570356472795498\n",
      "Epoch 18/100, Loss: 0.386078035619375, Val Accuracy: 0.7504690431519699\n",
      "Epoch 19/100, Loss: 0.37048898146170356, Val Accuracy: 0.7523452157598499\n",
      "Convergence reached, stopping training.\n",
      "Learning Rate: 0.001, Batch Size: 32 Optimizer: rmsprop, Validation Accuracy: 0.7570356472795498\n",
      "Training with the following hyperparameters:\n",
      "Learning Rate: 0.001, Batch Size: 64, Hidden Size: 128, Optimizer: adam\n",
      "Epoch 1/100, Loss: 0.5839825655097393, Val Accuracy: 0.7279549718574109\n",
      "Epoch 2/100, Loss: 0.5280642525028827, Val Accuracy: 0.7326454033771107\n",
      "Epoch 3/100, Loss: 0.50670638635977, Val Accuracy: 0.7213883677298312\n",
      "Epoch 4/100, Loss: 0.5011745386604053, Val Accuracy: 0.7326454033771107\n",
      "Epoch 5/100, Loss: 0.4840695893586571, Val Accuracy: 0.7485928705440901\n",
      "Epoch 6/100, Loss: 0.4719463766955618, Val Accuracy: 0.7579737335834896\n",
      "Epoch 7/100, Loss: 0.47022670930001276, Val Accuracy: 0.7420262664165104\n",
      "Epoch 8/100, Loss: 0.44452137689092264, Val Accuracy: 0.7589118198874296\n",
      "Epoch 9/100, Loss: 0.4409760694895218, Val Accuracy: 0.7457786116322702\n",
      "Epoch 10/100, Loss: 0.41824092460212425, Val Accuracy: 0.7532833020637899\n",
      "Epoch 11/100, Loss: 0.39417257070986195, Val Accuracy: 0.7532833020637899\n",
      "Epoch 12/100, Loss: 0.38130430109910113, Val Accuracy: 0.7589118198874296\n",
      "Epoch 13/100, Loss: 0.36484995450991303, Val Accuracy: 0.7420262664165104\n",
      "Epoch 14/100, Loss: 0.34411071507788416, Val Accuracy: 0.7457786116322702\n",
      "Epoch 15/100, Loss: 0.3038995660730262, Val Accuracy: 0.7532833020637899\n",
      "Epoch 16/100, Loss: 0.29929205135845427, Val Accuracy: 0.7457786116322702\n",
      "Epoch 17/100, Loss: 0.2563953125543559, Val Accuracy: 0.7457786116322702\n",
      "Epoch 18/100, Loss: 0.22927903072602712, Val Accuracy: 0.7429643527204502\n",
      "Convergence reached, stopping training.\n",
      "Learning Rate: 0.001, Batch Size: 64 Optimizer: adam, Validation Accuracy: 0.7589118198874296\n",
      "Training with the following hyperparameters:\n",
      "Learning Rate: 0.001, Batch Size: 64, Hidden Size: 128, Optimizer: sgd\n",
      "Epoch 1/100, Loss: 0.6955248571153897, Val Accuracy: 0.5\n",
      "Epoch 2/100, Loss: 0.6945881154110183, Val Accuracy: 0.5\n",
      "Epoch 3/100, Loss: 0.6938431343035911, Val Accuracy: 0.5\n",
      "Epoch 4/100, Loss: 0.6934129729199765, Val Accuracy: 0.50187617260788\n",
      "Epoch 5/100, Loss: 0.6931399738610681, Val Accuracy: 0.5037523452157598\n",
      "Epoch 6/100, Loss: 0.6929739967210969, Val Accuracy: 0.5131332082551595\n",
      "Epoch 7/100, Loss: 0.6927916705608368, Val Accuracy: 0.5337711069418386\n",
      "Epoch 8/100, Loss: 0.6926352719762432, Val Accuracy: 0.5272045028142589\n",
      "Epoch 9/100, Loss: 0.6925607443745456, Val Accuracy: 0.5225140712945591\n",
      "Epoch 10/100, Loss: 0.6924393706357301, Val Accuracy: 0.5215759849906192\n",
      "Epoch 11/100, Loss: 0.6923313292104807, Val Accuracy: 0.524390243902439\n",
      "Epoch 12/100, Loss: 0.6922179949817373, Val Accuracy: 0.5196998123827392\n",
      "Epoch 13/100, Loss: 0.692144311186093, Val Accuracy: 0.5225140712945591\n",
      "Epoch 14/100, Loss: 0.6920301816356715, Val Accuracy: 0.5318949343339587\n",
      "Epoch 15/100, Loss: 0.691975070469415, Val Accuracy: 0.5356472795497186\n",
      "Epoch 16/100, Loss: 0.6918557579837629, Val Accuracy: 0.5356472795497186\n",
      "Epoch 17/100, Loss: 0.691750597153137, Val Accuracy: 0.5403377110694184\n",
      "Epoch 18/100, Loss: 0.6916825126356153, Val Accuracy: 0.5412757973733584\n",
      "Epoch 19/100, Loss: 0.6915943386839397, Val Accuracy: 0.5422138836772983\n",
      "Epoch 20/100, Loss: 0.6914704215170732, Val Accuracy: 0.5431519699812383\n",
      "Epoch 21/100, Loss: 0.6914207499418685, Val Accuracy: 0.5478424015009381\n",
      "Epoch 22/100, Loss: 0.6913050244103617, Val Accuracy: 0.550656660412758\n",
      "Epoch 23/100, Loss: 0.6912739815107033, Val Accuracy: 0.5534709193245778\n",
      "Epoch 24/100, Loss: 0.6911193470456707, Val Accuracy: 0.5581613508442776\n",
      "Epoch 25/100, Loss: 0.6910305872781953, Val Accuracy: 0.5600375234521576\n",
      "Epoch 26/100, Loss: 0.6909182872345199, Val Accuracy: 0.5600375234521576\n",
      "Epoch 27/100, Loss: 0.6908339822470252, Val Accuracy: 0.5628517823639775\n",
      "Epoch 28/100, Loss: 0.6907285073799874, Val Accuracy: 0.5619136960600375\n",
      "Epoch 29/100, Loss: 0.6906744628699858, Val Accuracy: 0.5666041275797373\n",
      "Epoch 30/100, Loss: 0.6905653805875066, Val Accuracy: 0.5666041275797373\n",
      "Epoch 31/100, Loss: 0.6904371434183263, Val Accuracy: 0.5694183864915572\n",
      "Epoch 32/100, Loss: 0.6903410264805182, Val Accuracy: 0.574108818011257\n",
      "Epoch 33/100, Loss: 0.6902135913051776, Val Accuracy: 0.575046904315197\n",
      "Epoch 34/100, Loss: 0.6901410484491889, Val Accuracy: 0.5778611632270169\n",
      "Epoch 35/100, Loss: 0.689982170489297, Val Accuracy: 0.5806754221388368\n",
      "Epoch 36/100, Loss: 0.689927537494631, Val Accuracy: 0.5825515947467167\n",
      "Epoch 37/100, Loss: 0.6897993065528015, Val Accuracy: 0.5825515947467167\n",
      "Epoch 38/100, Loss: 0.6896861640375052, Val Accuracy: 0.5816135084427767\n",
      "Epoch 39/100, Loss: 0.6895478025301179, Val Accuracy: 0.5825515947467167\n",
      "Epoch 40/100, Loss: 0.6894088187324467, Val Accuracy: 0.5816135084427767\n",
      "Epoch 41/100, Loss: 0.689335778133193, Val Accuracy: 0.5825515947467167\n",
      "Epoch 42/100, Loss: 0.6891965399037546, Val Accuracy: 0.5844277673545967\n",
      "Epoch 43/100, Loss: 0.689066971415904, Val Accuracy: 0.5844277673545967\n",
      "Epoch 44/100, Loss: 0.6889527360005165, Val Accuracy: 0.5881801125703565\n",
      "Epoch 45/100, Loss: 0.6888260881402599, Val Accuracy: 0.5881801125703565\n",
      "Epoch 46/100, Loss: 0.6886805064642607, Val Accuracy: 0.5881801125703565\n",
      "Epoch 47/100, Loss: 0.6885146592090379, Val Accuracy: 0.5919324577861164\n",
      "Epoch 48/100, Loss: 0.6883463009969512, Val Accuracy: 0.5919324577861164\n",
      "Epoch 49/100, Loss: 0.6881722505412885, Val Accuracy: 0.5938086303939962\n",
      "Epoch 50/100, Loss: 0.6880786485636412, Val Accuracy: 0.5919324577861164\n",
      "Epoch 51/100, Loss: 0.6879064560826145, Val Accuracy: 0.5956848030018762\n",
      "Epoch 52/100, Loss: 0.6877821368068012, Val Accuracy: 0.5966228893058161\n",
      "Epoch 53/100, Loss: 0.68767187577575, Val Accuracy: 0.5975609756097561\n",
      "Epoch 54/100, Loss: 0.6874638399971065, Val Accuracy: 0.6022514071294559\n",
      "Epoch 55/100, Loss: 0.6872990069104664, Val Accuracy: 0.6031894934333959\n",
      "Epoch 56/100, Loss: 0.6870983741176662, Val Accuracy: 0.6022514071294559\n",
      "Epoch 57/100, Loss: 0.6868455192046379, Val Accuracy: 0.599437148217636\n",
      "Epoch 58/100, Loss: 0.6867325728508964, Val Accuracy: 0.6022514071294559\n",
      "Epoch 59/100, Loss: 0.6864719404213464, Val Accuracy: 0.6069418386491557\n",
      "Epoch 60/100, Loss: 0.6862488682590314, Val Accuracy: 0.6125703564727955\n",
      "Epoch 61/100, Loss: 0.6861109017436184, Val Accuracy: 0.6097560975609756\n",
      "Epoch 62/100, Loss: 0.6858549322654952, Val Accuracy: 0.6106941838649156\n",
      "Epoch 63/100, Loss: 0.6856848041513073, Val Accuracy: 0.6116322701688556\n",
      "Epoch 64/100, Loss: 0.685362549860086, Val Accuracy: 0.6088180112570356\n",
      "Epoch 65/100, Loss: 0.6851134193477346, Val Accuracy: 0.6116322701688556\n",
      "Epoch 66/100, Loss: 0.6848993795131569, Val Accuracy: 0.6116322701688556\n",
      "Epoch 67/100, Loss: 0.6846411695231253, Val Accuracy: 0.6106941838649156\n",
      "Epoch 68/100, Loss: 0.6843392150615578, Val Accuracy: 0.6125703564727955\n",
      "Epoch 69/100, Loss: 0.6839860077224561, Val Accuracy: 0.6116322701688556\n",
      "Epoch 70/100, Loss: 0.683792176531322, Val Accuracy: 0.6135084427767354\n",
      "Epoch 71/100, Loss: 0.6834102864585706, Val Accuracy: 0.6163227016885553\n",
      "Epoch 72/100, Loss: 0.6831055363612388, Val Accuracy: 0.6181988742964353\n",
      "Epoch 73/100, Loss: 0.68275774637265, Val Accuracy: 0.6191369606003753\n",
      "Epoch 74/100, Loss: 0.6823608212506593, Val Accuracy: 0.6200750469043153\n",
      "Epoch 75/100, Loss: 0.6819339843828287, Val Accuracy: 0.6210131332082551\n",
      "Epoch 76/100, Loss: 0.681630461963255, Val Accuracy: 0.6219512195121951\n",
      "Epoch 77/100, Loss: 0.6810856021162289, Val Accuracy: 0.626641651031895\n",
      "Epoch 78/100, Loss: 0.6807200717392252, Val Accuracy: 0.6275797373358349\n",
      "Epoch 79/100, Loss: 0.6801089092866698, Val Accuracy: 0.6275797373358349\n",
      "Epoch 80/100, Loss: 0.6797166319925394, Val Accuracy: 0.6275797373358349\n",
      "Epoch 81/100, Loss: 0.679008462980612, Val Accuracy: 0.625703564727955\n",
      "Epoch 82/100, Loss: 0.6785131915291743, Val Accuracy: 0.626641651031895\n",
      "Epoch 83/100, Loss: 0.677878427416531, Val Accuracy: 0.6285178236397748\n",
      "Epoch 84/100, Loss: 0.6772213555983643, Val Accuracy: 0.6285178236397748\n",
      "Epoch 85/100, Loss: 0.6763539136345706, Val Accuracy: 0.6285178236397748\n",
      "Epoch 86/100, Loss: 0.6756080171065544, Val Accuracy: 0.6313320825515948\n",
      "Epoch 87/100, Loss: 0.6747248737669703, Val Accuracy: 0.6322701688555347\n",
      "Epoch 88/100, Loss: 0.673758686923269, Val Accuracy: 0.6360225140712945\n",
      "Epoch 89/100, Loss: 0.6726360632412469, Val Accuracy: 0.6369606003752345\n",
      "Epoch 90/100, Loss: 0.6718111554188515, Val Accuracy: 0.6425891181988743\n",
      "Epoch 91/100, Loss: 0.6703166828226688, Val Accuracy: 0.6397748592870544\n",
      "Epoch 92/100, Loss: 0.6690184264930327, Val Accuracy: 0.6444652908067542\n",
      "Epoch 93/100, Loss: 0.6673459966680897, Val Accuracy: 0.6425891181988743\n",
      "Epoch 94/100, Loss: 0.6657596888826854, Val Accuracy: 0.6416510318949343\n",
      "Epoch 95/100, Loss: 0.6638426447092597, Val Accuracy: 0.6435272045028143\n",
      "Epoch 96/100, Loss: 0.6616782030062889, Val Accuracy: 0.6435272045028143\n",
      "Epoch 97/100, Loss: 0.6591285364841347, Val Accuracy: 0.651031894934334\n",
      "Epoch 98/100, Loss: 0.6562487425199196, Val Accuracy: 0.651031894934334\n",
      "Epoch 99/100, Loss: 0.6529231734240233, Val Accuracy: 0.6557223264540337\n",
      "Epoch 100/100, Loss: 0.6489823829771867, Val Accuracy: 0.6613508442776735\n",
      "Learning Rate: 0.001, Batch Size: 64 Optimizer: sgd, Validation Accuracy: 0.6613508442776735\n",
      "Training with the following hyperparameters:\n",
      "Learning Rate: 0.001, Batch Size: 64, Hidden Size: 128, Optimizer: rmsprop\n",
      "Epoch 1/100, Loss: 0.6287724133302917, Val Accuracy: 0.6894934333958724\n",
      "Epoch 2/100, Loss: 0.555686338179147, Val Accuracy: 0.6941838649155723\n",
      "Epoch 3/100, Loss: 0.5307550583757571, Val Accuracy: 0.7345215759849906\n",
      "Epoch 4/100, Loss: 0.5072460777279156, Val Accuracy: 0.7091932457786116\n",
      "Epoch 5/100, Loss: 0.5048423089198212, Val Accuracy: 0.7326454033771107\n",
      "Epoch 6/100, Loss: 0.49299366104958664, Val Accuracy: 0.7138836772983115\n",
      "Epoch 7/100, Loss: 0.4879493668897828, Val Accuracy: 0.7345215759849906\n",
      "Epoch 8/100, Loss: 0.4786831271737369, Val Accuracy: 0.725140712945591\n",
      "Epoch 9/100, Loss: 0.474178986985292, Val Accuracy: 0.7551594746716698\n",
      "Epoch 10/100, Loss: 0.46187597179590767, Val Accuracy: 0.7448405253283302\n",
      "Epoch 11/100, Loss: 0.4551634659518057, Val Accuracy: 0.7401500938086304\n",
      "Epoch 12/100, Loss: 0.4519006605468579, Val Accuracy: 0.6688555347091932\n",
      "Epoch 13/100, Loss: 0.446801823244166, Val Accuracy: 0.7363977485928705\n",
      "Epoch 14/100, Loss: 0.43423375643011347, Val Accuracy: 0.7523452157598499\n",
      "Epoch 15/100, Loss: 0.4264810152018248, Val Accuracy: 0.7354596622889306\n",
      "Epoch 16/100, Loss: 0.4199965362673375, Val Accuracy: 0.7448405253283302\n",
      "Epoch 17/100, Loss: 0.4244441897121828, Val Accuracy: 0.7288930581613509\n",
      "Epoch 18/100, Loss: 0.4176555091320579, Val Accuracy: 0.7401500938086304\n",
      "Epoch 19/100, Loss: 0.4032303127112673, Val Accuracy: 0.7401500938086304\n",
      "Convergence reached, stopping training.\n",
      "Learning Rate: 0.001, Batch Size: 64 Optimizer: rmsprop, Validation Accuracy: 0.7551594746716698\n",
      "Training with the following hyperparameters:\n",
      "Learning Rate: 0.01, Batch Size: 32, Hidden Size: 128, Optimizer: adam\n",
      "Epoch 1/100, Loss: 0.7021985728195991, Val Accuracy: 0.50093808630394\n",
      "Epoch 2/100, Loss: 0.7099645276194655, Val Accuracy: 0.49530956848030017\n",
      "Epoch 3/100, Loss: 0.7089547878794009, Val Accuracy: 0.5\n",
      "Epoch 4/100, Loss: 0.7051025381248989, Val Accuracy: 0.5075046904315197\n",
      "Epoch 5/100, Loss: 0.707972561598717, Val Accuracy: 0.573170731707317\n",
      "Epoch 6/100, Loss: 0.7096755861789547, Val Accuracy: 0.5609756097560976\n",
      "Epoch 7/100, Loss: 0.6940734118558047, Val Accuracy: 0.5206378986866792\n",
      "Epoch 8/100, Loss: 0.6735007555297251, Val Accuracy: 0.5712945590994372\n",
      "Epoch 9/100, Loss: 0.6949449239598677, Val Accuracy: 0.600375234521576\n",
      "Epoch 10/100, Loss: 0.6830669355749638, Val Accuracy: 0.5\n",
      "Epoch 11/100, Loss: 0.6813677509179276, Val Accuracy: 0.5834896810506567\n",
      "Epoch 12/100, Loss: 0.6821186176400059, Val Accuracy: 0.5028142589118199\n",
      "Epoch 13/100, Loss: 0.6607224238052797, Val Accuracy: 0.5844277673545967\n",
      "Epoch 14/100, Loss: 0.649544064360165, Val Accuracy: 0.625703564727955\n",
      "Epoch 15/100, Loss: 0.6292654698930876, Val Accuracy: 0.6575984990619137\n",
      "Epoch 16/100, Loss: 0.6525458266002855, Val Accuracy: 0.6416510318949343\n",
      "Epoch 17/100, Loss: 0.625420292665003, Val Accuracy: 0.6454033771106942\n",
      "Epoch 18/100, Loss: 0.6235139327549309, Val Accuracy: 0.6575984990619137\n",
      "Epoch 19/100, Loss: 0.5939882722463501, Val Accuracy: 0.6416510318949343\n",
      "Epoch 20/100, Loss: 0.6026779425501377, Val Accuracy: 0.6735459662288931\n",
      "Epoch 21/100, Loss: 0.604952823579981, Val Accuracy: 0.6294559099437148\n",
      "Epoch 22/100, Loss: 0.5872140527887737, Val Accuracy: 0.6660412757973734\n",
      "Epoch 23/100, Loss: 0.6225874586944723, Val Accuracy: 0.6454033771106942\n",
      "Epoch 24/100, Loss: 0.6389927915419532, Val Accuracy: 0.6163227016885553\n",
      "Epoch 25/100, Loss: 0.6070036402579104, Val Accuracy: 0.6594746716697936\n",
      "Epoch 26/100, Loss: 0.5884839147887426, Val Accuracy: 0.6463414634146342\n",
      "Epoch 27/100, Loss: 0.5878783049208395, Val Accuracy: 0.6294559099437148\n",
      "Epoch 28/100, Loss: 0.5938301738281822, Val Accuracy: 0.6801125703564728\n",
      "Epoch 29/100, Loss: 0.5934500202034296, Val Accuracy: 0.5872420262664165\n",
      "Epoch 30/100, Loss: 0.5987701080041878, Val Accuracy: 0.6801125703564728\n",
      "Epoch 31/100, Loss: 0.5932085467188546, Val Accuracy: 0.6463414634146342\n",
      "Epoch 32/100, Loss: 0.5856329289714942, Val Accuracy: 0.6726078799249531\n",
      "Epoch 33/100, Loss: 0.5774206890818778, Val Accuracy: 0.701688555347092\n",
      "Epoch 34/100, Loss: 0.5932121649663546, Val Accuracy: 0.6688555347091932\n",
      "Epoch 35/100, Loss: 0.5993617626834898, Val Accuracy: 0.649155722326454\n",
      "Epoch 36/100, Loss: 0.592325992017203, Val Accuracy: 0.6538461538461539\n",
      "Epoch 37/100, Loss: 0.5774672745765371, Val Accuracy: 0.6407129455909943\n",
      "Epoch 38/100, Loss: 0.58265782619237, Val Accuracy: 0.6932457786116323\n",
      "Epoch 39/100, Loss: 0.5712740907954813, Val Accuracy: 0.6707317073170732\n",
      "Epoch 40/100, Loss: 0.5705701004476583, Val Accuracy: 0.7045028142589118\n",
      "Epoch 41/100, Loss: 0.617022991850135, Val Accuracy: 0.6444652908067542\n",
      "Epoch 42/100, Loss: 0.6022465724623605, Val Accuracy: 0.6857410881801126\n",
      "Epoch 43/100, Loss: 0.60286694619986, Val Accuracy: 0.5863039399624765\n",
      "Epoch 44/100, Loss: 0.5835736283425534, Val Accuracy: 0.6838649155722326\n",
      "Epoch 45/100, Loss: 0.5750680983289798, Val Accuracy: 0.6744840525328331\n",
      "Epoch 46/100, Loss: 0.5702118157001024, Val Accuracy: 0.6969981238273921\n",
      "Epoch 47/100, Loss: 0.5660831777567275, Val Accuracy: 0.6125703564727955\n",
      "Epoch 48/100, Loss: 0.5848812762271153, Val Accuracy: 0.6932457786116323\n",
      "Epoch 49/100, Loss: 0.5597387923953239, Val Accuracy: 0.6932457786116323\n",
      "Epoch 50/100, Loss: 0.5629038993785443, Val Accuracy: 0.6904315196998124\n",
      "Convergence reached, stopping training.\n",
      "Learning Rate: 0.01, Batch Size: 32 Optimizer: adam, Validation Accuracy: 0.7045028142589118\n",
      "Training with the following hyperparameters:\n",
      "Learning Rate: 0.01, Batch Size: 32, Hidden Size: 128, Optimizer: sgd\n",
      "Epoch 1/100, Loss: 0.6922049855025073, Val Accuracy: 0.5037523452157598\n",
      "Epoch 2/100, Loss: 0.6904330195559099, Val Accuracy: 0.551594746716698\n",
      "Epoch 3/100, Loss: 0.6877352081881034, Val Accuracy: 0.6106941838649156\n",
      "Epoch 4/100, Loss: 0.6822860216380059, Val Accuracy: 0.6360225140712945\n",
      "Epoch 5/100, Loss: 0.6610931586683466, Val Accuracy: 0.5666041275797373\n",
      "Epoch 6/100, Loss: 0.6095433717363337, Val Accuracy: 0.6951219512195121\n",
      "Epoch 7/100, Loss: 0.577468654524521, Val Accuracy: 0.725140712945591\n",
      "Epoch 8/100, Loss: 0.5591846080531788, Val Accuracy: 0.723264540337711\n",
      "Epoch 9/100, Loss: 0.5542071660359701, Val Accuracy: 0.7157598499061913\n",
      "Epoch 10/100, Loss: 0.5417766134613908, Val Accuracy: 0.6707317073170732\n",
      "Epoch 11/100, Loss: 0.5332113671838568, Val Accuracy: 0.6819887429643527\n",
      "Epoch 12/100, Loss: 0.5251493209533478, Val Accuracy: 0.723264540337711\n",
      "Epoch 13/100, Loss: 0.5171430372120289, Val Accuracy: 0.7307692307692307\n",
      "Epoch 14/100, Loss: 0.516871276754565, Val Accuracy: 0.7166979362101313\n",
      "Epoch 15/100, Loss: 0.5143591759356667, Val Accuracy: 0.7335834896810507\n",
      "Epoch 16/100, Loss: 0.511703143963653, Val Accuracy: 0.7335834896810507\n",
      "Epoch 17/100, Loss: 0.5038846170299509, Val Accuracy: 0.7279549718574109\n",
      "Epoch 18/100, Loss: 0.500947328430883, Val Accuracy: 0.6819887429643527\n",
      "Epoch 19/100, Loss: 0.5000427969162831, Val Accuracy: 0.7138836772983115\n",
      "Epoch 20/100, Loss: 0.49919327959585724, Val Accuracy: 0.7420262664165104\n",
      "Epoch 21/100, Loss: 0.4965909781973907, Val Accuracy: 0.6332082551594747\n",
      "Epoch 22/100, Loss: 0.49415135707301594, Val Accuracy: 0.7401500938086304\n",
      "Epoch 23/100, Loss: 0.4933396661549472, Val Accuracy: 0.7476547842401501\n",
      "Epoch 24/100, Loss: 0.49076870563771396, Val Accuracy: 0.7223264540337712\n",
      "Epoch 25/100, Loss: 0.4918041035030665, Val Accuracy: 0.7532833020637899\n",
      "Epoch 26/100, Loss: 0.48766689008094843, Val Accuracy: 0.7457786116322702\n",
      "Epoch 27/100, Loss: 0.4823042710733771, Val Accuracy: 0.7073170731707317\n",
      "Epoch 28/100, Loss: 0.4861043758606643, Val Accuracy: 0.7223264540337712\n",
      "Epoch 29/100, Loss: 0.4826554035426079, Val Accuracy: 0.7157598499061913\n",
      "Epoch 30/100, Loss: 0.4769855541236392, Val Accuracy: 0.7514071294559099\n",
      "Epoch 31/100, Loss: 0.48106720362709704, Val Accuracy: 0.7335834896810507\n",
      "Epoch 32/100, Loss: 0.4765112234858538, Val Accuracy: 0.7157598499061913\n",
      "Epoch 33/100, Loss: 0.47723938184284537, Val Accuracy: 0.7401500938086304\n",
      "Epoch 34/100, Loss: 0.474434723679939, Val Accuracy: 0.6866791744840526\n",
      "Epoch 35/100, Loss: 0.47427348284685655, Val Accuracy: 0.7148217636022514\n",
      "Convergence reached, stopping training.\n",
      "Learning Rate: 0.01, Batch Size: 32 Optimizer: sgd, Validation Accuracy: 0.7532833020637899\n",
      "Training with the following hyperparameters:\n",
      "Learning Rate: 0.01, Batch Size: 32, Hidden Size: 128, Optimizer: rmsprop\n",
      "Epoch 1/100, Loss: 0.7317212404829733, Val Accuracy: 0.5\n",
      "Epoch 2/100, Loss: 0.7128841894842712, Val Accuracy: 0.5\n",
      "Epoch 3/100, Loss: 0.701112061180872, Val Accuracy: 0.50093808630394\n",
      "Epoch 4/100, Loss: 0.7084847215409582, Val Accuracy: 0.50187617260788\n",
      "Epoch 5/100, Loss: 0.7019125973240713, Val Accuracy: 0.5\n",
      "Epoch 6/100, Loss: 0.7032121741369869, Val Accuracy: 0.5028142589118199\n",
      "Epoch 7/100, Loss: 0.7065477331032913, Val Accuracy: 0.4971857410881801\n",
      "Epoch 8/100, Loss: 0.6922127626808395, Val Accuracy: 0.5544090056285178\n",
      "Epoch 9/100, Loss: 0.6839928939547878, Val Accuracy: 0.5046904315196998\n",
      "Epoch 10/100, Loss: 0.6802831314476242, Val Accuracy: 0.5637898686679175\n",
      "Epoch 11/100, Loss: 0.682440543665868, Val Accuracy: 0.5619136960600375\n",
      "Epoch 12/100, Loss: 0.6881059330054436, Val Accuracy: 0.5084427767354597\n",
      "Epoch 13/100, Loss: 0.6890252116467622, Val Accuracy: 0.5769230769230769\n",
      "Epoch 14/100, Loss: 0.6816154093331612, Val Accuracy: 0.5412757973733584\n",
      "Epoch 15/100, Loss: 0.6777580036652668, Val Accuracy: 0.5863039399624765\n",
      "Epoch 16/100, Loss: 0.6873266187946449, Val Accuracy: 0.50093808630394\n",
      "Epoch 17/100, Loss: 0.7156341899646802, Val Accuracy: 0.5431519699812383\n",
      "Epoch 18/100, Loss: 0.7463184820578785, Val Accuracy: 0.5121951219512195\n",
      "Epoch 19/100, Loss: 0.7287542654780413, Val Accuracy: 0.5562851782363978\n",
      "Epoch 20/100, Loss: 0.7290257019050113, Val Accuracy: 0.50187617260788\n",
      "Epoch 21/100, Loss: 0.7247385239779726, Val Accuracy: 0.5046904315196998\n",
      "Epoch 22/100, Loss: 0.7161477337615767, Val Accuracy: 0.5619136960600375\n",
      "Epoch 23/100, Loss: 0.704907496770223, Val Accuracy: 0.5300187617260788\n",
      "Epoch 24/100, Loss: 0.7043395459875186, Val Accuracy: 0.5469043151969981\n",
      "Epoch 25/100, Loss: 0.7288159015919832, Val Accuracy: 0.5093808630393997\n",
      "Convergence reached, stopping training.\n",
      "Learning Rate: 0.01, Batch Size: 32 Optimizer: rmsprop, Validation Accuracy: 0.5863039399624765\n",
      "Training with the following hyperparameters:\n",
      "Learning Rate: 0.01, Batch Size: 64, Hidden Size: 128, Optimizer: adam\n",
      "Epoch 1/100, Loss: 0.6949807881419339, Val Accuracy: 0.5131332082551595\n",
      "Epoch 2/100, Loss: 0.6920416088246587, Val Accuracy: 0.5\n",
      "Epoch 3/100, Loss: 0.6936242829507856, Val Accuracy: 0.5637898686679175\n",
      "Epoch 4/100, Loss: 0.663560374459224, Val Accuracy: 0.6153846153846154\n",
      "Epoch 5/100, Loss: 0.6413394410663577, Val Accuracy: 0.5919324577861164\n",
      "Epoch 6/100, Loss: 0.6363935515062132, Val Accuracy: 0.6416510318949343\n",
      "Epoch 7/100, Loss: 0.6136269360335905, Val Accuracy: 0.6679174484052532\n",
      "Epoch 8/100, Loss: 0.6085337509415043, Val Accuracy: 0.6707317073170732\n",
      "Epoch 9/100, Loss: 0.6121396242237803, Val Accuracy: 0.6632270168855535\n",
      "Epoch 10/100, Loss: 0.5971297292567012, Val Accuracy: 0.6013133208255159\n",
      "Epoch 11/100, Loss: 0.651805210469374, Val Accuracy: 0.651031894934334\n",
      "Epoch 12/100, Loss: 0.6279364130390224, Val Accuracy: 0.6350844277673546\n",
      "Epoch 13/100, Loss: 0.6343514805854257, Val Accuracy: 0.6088180112570356\n",
      "Epoch 14/100, Loss: 0.6277821313089399, Val Accuracy: 0.6622889305816135\n",
      "Epoch 15/100, Loss: 0.6457654340053672, Val Accuracy: 0.6135084427767354\n",
      "Epoch 16/100, Loss: 0.6540781352947007, Val Accuracy: 0.6125703564727955\n",
      "Epoch 17/100, Loss: 0.6593771590225732, Val Accuracy: 0.6238273921200751\n",
      "Epoch 18/100, Loss: 0.6489739818359489, Val Accuracy: 0.5347091932457786\n",
      "Convergence reached, stopping training.\n",
      "Learning Rate: 0.01, Batch Size: 64 Optimizer: adam, Validation Accuracy: 0.6707317073170732\n",
      "Training with the following hyperparameters:\n",
      "Learning Rate: 0.01, Batch Size: 64, Hidden Size: 128, Optimizer: sgd\n",
      "Epoch 1/100, Loss: 0.6926920249390958, Val Accuracy: 0.5037523452157598\n",
      "Epoch 2/100, Loss: 0.6918390918133864, Val Accuracy: 0.5590994371482176\n",
      "Epoch 3/100, Loss: 0.690925078605538, Val Accuracy: 0.6125703564727955\n",
      "Epoch 4/100, Loss: 0.6899835752017462, Val Accuracy: 0.5787992495309568\n",
      "Epoch 5/100, Loss: 0.6888649517030858, Val Accuracy: 0.5947467166979362\n",
      "Epoch 6/100, Loss: 0.6876559279747864, Val Accuracy: 0.6116322701688556\n",
      "Epoch 7/100, Loss: 0.6860262978432784, Val Accuracy: 0.575046904315197\n",
      "Epoch 8/100, Loss: 0.6839618567210525, Val Accuracy: 0.6369606003752345\n",
      "Epoch 9/100, Loss: 0.6811372539890346, Val Accuracy: 0.6360225140712945\n",
      "Epoch 10/100, Loss: 0.6767131881927376, Val Accuracy: 0.6332082551594747\n",
      "Epoch 11/100, Loss: 0.6685603105310184, Val Accuracy: 0.6557223264540337\n",
      "Epoch 12/100, Loss: 0.6500416691623517, Val Accuracy: 0.6613508442776735\n",
      "Epoch 13/100, Loss: 0.6135066076001124, Val Accuracy: 0.6378986866791745\n",
      "Epoch 14/100, Loss: 0.5906917123652217, Val Accuracy: 0.5656660412757973\n",
      "Epoch 15/100, Loss: 0.5803996564737007, Val Accuracy: 0.6275797373358349\n",
      "Epoch 16/100, Loss: 0.5741181631586445, Val Accuracy: 0.6454033771106942\n",
      "Epoch 17/100, Loss: 0.5549355024722085, Val Accuracy: 0.6726078799249531\n",
      "Epoch 18/100, Loss: 0.5452934154378835, Val Accuracy: 0.7045028142589118\n",
      "Epoch 19/100, Loss: 0.5430057391301909, Val Accuracy: 0.7166979362101313\n",
      "Epoch 20/100, Loss: 0.539187907950202, Val Accuracy: 0.6735459662288931\n",
      "Epoch 21/100, Loss: 0.5386355955209305, Val Accuracy: 0.649155722326454\n",
      "Epoch 22/100, Loss: 0.5276367928999574, Val Accuracy: 0.724202626641651\n",
      "Epoch 23/100, Loss: 0.5228278365597796, Val Accuracy: 0.7204502814258912\n",
      "Epoch 24/100, Loss: 0.5147229235118894, Val Accuracy: 0.725140712945591\n",
      "Epoch 25/100, Loss: 0.5195842205143687, Val Accuracy: 0.5909943714821764\n",
      "Epoch 26/100, Loss: 0.5136659957134901, Val Accuracy: 0.6894934333958724\n",
      "Epoch 27/100, Loss: 0.5103764373864701, Val Accuracy: 0.6097560975609756\n",
      "Epoch 28/100, Loss: 0.506510103371606, Val Accuracy: 0.5872420262664165\n",
      "Epoch 29/100, Loss: 0.5081706847717513, Val Accuracy: 0.7213883677298312\n",
      "Epoch 30/100, Loss: 0.5055862553973696, Val Accuracy: 0.599437148217636\n",
      "Epoch 31/100, Loss: 0.508665172911402, Val Accuracy: 0.5853658536585366\n",
      "Epoch 32/100, Loss: 0.5038586694802811, Val Accuracy: 0.7298311444652908\n",
      "Epoch 33/100, Loss: 0.4968125250802111, Val Accuracy: 0.7392120075046904\n",
      "Epoch 34/100, Loss: 0.4998753900403407, Val Accuracy: 0.7335834896810507\n",
      "Epoch 35/100, Loss: 0.4898945517949204, Val Accuracy: 0.7429643527204502\n",
      "Epoch 36/100, Loss: 0.4961988129722538, Val Accuracy: 0.7363977485928705\n",
      "Epoch 37/100, Loss: 0.4927762697881727, Val Accuracy: 0.6848030018761726\n",
      "Epoch 38/100, Loss: 0.4901582821091609, Val Accuracy: 0.7354596622889306\n",
      "Epoch 39/100, Loss: 0.49077138126786074, Val Accuracy: 0.7035647279549718\n",
      "Epoch 40/100, Loss: 0.4895190967997508, Val Accuracy: 0.6913696060037523\n",
      "Epoch 41/100, Loss: 0.4898182396123658, Val Accuracy: 0.7439024390243902\n",
      "Epoch 42/100, Loss: 0.49251679964919587, Val Accuracy: 0.7439024390243902\n",
      "Epoch 43/100, Loss: 0.4817852958369611, Val Accuracy: 0.7129455909943715\n",
      "Epoch 44/100, Loss: 0.48031156298829547, Val Accuracy: 0.7523452157598499\n",
      "Epoch 45/100, Loss: 0.4834958959871264, Val Accuracy: 0.6772983114446529\n",
      "Epoch 46/100, Loss: 0.48486293629923866, Val Accuracy: 0.7523452157598499\n",
      "Epoch 47/100, Loss: 0.4802463795266934, Val Accuracy: 0.7467166979362101\n",
      "Epoch 48/100, Loss: 0.4804138158684346, Val Accuracy: 0.7523452157598499\n",
      "Epoch 49/100, Loss: 0.4748616396491207, Val Accuracy: 0.7448405253283302\n",
      "Epoch 50/100, Loss: 0.4791622172985504, Val Accuracy: 0.7467166979362101\n",
      "Epoch 51/100, Loss: 0.47387105182035644, Val Accuracy: 0.7223264540337712\n",
      "Epoch 52/100, Loss: 0.4718468707444063, Val Accuracy: 0.7542213883677298\n",
      "Epoch 53/100, Loss: 0.47745226323604584, Val Accuracy: 0.7457786116322702\n",
      "Epoch 54/100, Loss: 0.4717192058242969, Val Accuracy: 0.7120075046904315\n",
      "Epoch 55/100, Loss: 0.4759288794958769, Val Accuracy: 0.6951219512195121\n",
      "Epoch 56/100, Loss: 0.47582649428453017, Val Accuracy: 0.726078799249531\n",
      "Epoch 57/100, Loss: 0.4730168167334884, Val Accuracy: 0.726078799249531\n",
      "Epoch 58/100, Loss: 0.47227232758678606, Val Accuracy: 0.7363977485928705\n",
      "Epoch 59/100, Loss: 0.47301080756223024, Val Accuracy: 0.7448405253283302\n",
      "Epoch 60/100, Loss: 0.47324945855496536, Val Accuracy: 0.7523452157598499\n",
      "Epoch 61/100, Loss: 0.46758990301125086, Val Accuracy: 0.7523452157598499\n",
      "Epoch 62/100, Loss: 0.46420802198239225, Val Accuracy: 0.6557223264540337\n",
      "Convergence reached, stopping training.\n",
      "Learning Rate: 0.01, Batch Size: 64 Optimizer: sgd, Validation Accuracy: 0.7542213883677298\n",
      "Training with the following hyperparameters:\n",
      "Learning Rate: 0.01, Batch Size: 64, Hidden Size: 128, Optimizer: rmsprop\n",
      "Epoch 1/100, Loss: 0.712283512104803, Val Accuracy: 0.5028142589118199\n",
      "Epoch 2/100, Loss: 0.6938310959445897, Val Accuracy: 0.5028142589118199\n",
      "Epoch 3/100, Loss: 0.692352521330563, Val Accuracy: 0.5440900562851783\n",
      "Epoch 4/100, Loss: 0.6846747829842923, Val Accuracy: 0.5131332082551595\n",
      "Epoch 5/100, Loss: 0.6815007400156846, Val Accuracy: 0.5825515947467167\n",
      "Epoch 6/100, Loss: 0.678819518480728, Val Accuracy: 0.5459662288930581\n",
      "Epoch 7/100, Loss: 0.6881093840990493, Val Accuracy: 0.5384615384615384\n",
      "Epoch 8/100, Loss: 0.7005317629273258, Val Accuracy: 0.50093808630394\n",
      "Epoch 9/100, Loss: 0.6900748107860337, Val Accuracy: 0.550656660412758\n",
      "Epoch 10/100, Loss: 0.7592502440979232, Val Accuracy: 0.5\n",
      "Epoch 11/100, Loss: 0.7290702969280641, Val Accuracy: 0.5225140712945591\n",
      "Epoch 12/100, Loss: 0.7197299759779403, Val Accuracy: 0.5\n",
      "Epoch 13/100, Loss: 0.7191167460448706, Val Accuracy: 0.5\n",
      "Epoch 14/100, Loss: 0.718493322383112, Val Accuracy: 0.5\n",
      "Epoch 15/100, Loss: 0.6772634051184157, Val Accuracy: 0.6341463414634146\n",
      "Epoch 16/100, Loss: 0.6523705972219581, Val Accuracy: 0.6688555347091932\n",
      "Epoch 17/100, Loss: 0.601423576029379, Val Accuracy: 0.7054409005628518\n",
      "Epoch 18/100, Loss: 0.5927539296559433, Val Accuracy: 0.724202626641651\n",
      "Epoch 19/100, Loss: 0.5850788283703933, Val Accuracy: 0.5412757973733584\n",
      "Epoch 20/100, Loss: 0.5848060134631484, Val Accuracy: 0.6604127579737336\n",
      "Epoch 21/100, Loss: 0.6015899468268922, Val Accuracy: 0.5938086303939962\n",
      "Epoch 22/100, Loss: 0.5829158796748118, Val Accuracy: 0.6876172607879925\n",
      "Epoch 23/100, Loss: 0.5877663039449436, Val Accuracy: 0.6303939962476548\n",
      "Epoch 24/100, Loss: 0.578815802042164, Val Accuracy: 0.6857410881801126\n",
      "Epoch 25/100, Loss: 0.5846005689297149, Val Accuracy: 0.6622889305816135\n",
      "Epoch 26/100, Loss: 0.5884506262060422, Val Accuracy: 0.6876172607879925\n",
      "Epoch 27/100, Loss: 0.5967564989826573, Val Accuracy: 0.625703564727955\n",
      "Epoch 28/100, Loss: 0.6355377871598771, Val Accuracy: 0.5984990619136961\n",
      "Convergence reached, stopping training.\n",
      "Learning Rate: 0.01, Batch Size: 64 Optimizer: rmsprop, Validation Accuracy: 0.724202626641651\n",
      "Best Model Configuration: {'learning_rate': 0.001, 'batch_size': 32, 'optimizer': 'adam'} with Validation Accuracy: 0.7626641651031895 over 19 epochs\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "learning_rates = [0.001, 0.01]\n",
    "batch_sizes = [32, 64]\n",
    "hidden_size = 128\n",
    "optimizers = ['adam', 'sgd', 'rmsprop']  \n",
    "\n",
    "vocab_size, embedding_dim = embedding_matrix_array.shape\n",
    "output_size = 1  \n",
    "\n",
    "best_val_acc = 0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "            for opt in optimizers:\n",
    "                print(\"Training with the following hyperparameters:\")\n",
    "                print(f\"Learning Rate: {lr}, Batch Size: {bs}, Hidden Size: {hidden_size}, Optimizer: {opt}\")\n",
    "                # Initialize model, criterion\n",
    "                model = RNNModel(embedding_matrix_array, hidden_size=128, output_size=1)\n",
    "                criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "                # Initialize optimizer based on the selected type\n",
    "                if opt == 'adam':\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "                elif opt == 'sgd':\n",
    "                    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "                elif opt == 'rmsprop':\n",
    "                    optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "\n",
    "                train_loader = create_data_loader(train_dataset_instance, bs)\n",
    "                val_loader = create_data_loader(val_dataset_instance, bs)\n",
    "                \n",
    "                # Train and validate\n",
    "                val_acc, epochs_used = train_and_validate(model, train_loader, val_loader, optimizer, criterion)\n",
    "                print(f\"Learning Rate: {lr}, Batch Size: {bs} Optimizer: {opt}, Validation Accuracy: {val_acc}\")\n",
    "\n",
    "                # Update best parameters\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_hyperparams = {\n",
    "                        'learning_rate': lr,\n",
    "                        'batch_size': bs,\n",
    "                        'optimizer': opt\n",
    "                    }\n",
    "                    best_epochs = epochs_used\n",
    "\n",
    "# Print the best configuration\n",
    "print(f\"Best Model Configuration: {best_hyperparams} with Validation Accuracy: {best_val_acc} over {best_epochs} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.576576258136092, Val Accuracy: 0.7213883677298312\n",
      "Epoch 2/100, Loss: 0.521774230155159, Val Accuracy: 0.7298311444652908\n",
      "Epoch 3/100, Loss: 0.5068495542034228, Val Accuracy: 0.6454033771106942\n",
      "Epoch 4/100, Loss: 0.5062251841084341, Val Accuracy: 0.7373358348968105\n",
      "Epoch 5/100, Loss: 0.5072163670473777, Val Accuracy: 0.7204502814258912\n",
      "Epoch 6/100, Loss: 0.48705723156196795, Val Accuracy: 0.7401500938086304\n",
      "Epoch 7/100, Loss: 0.46627063574862393, Val Accuracy: 0.7542213883677298\n",
      "Epoch 8/100, Loss: 0.45223133143191035, Val Accuracy: 0.7542213883677298\n",
      "Epoch 9/100, Loss: 0.4401021102506123, Val Accuracy: 0.7495309568480301\n",
      "Epoch 10/100, Loss: 0.42683407340603374, Val Accuracy: 0.7354596622889306\n",
      "Epoch 11/100, Loss: 0.4197735022962763, Val Accuracy: 0.7514071294559099\n",
      "Epoch 12/100, Loss: 0.40088874347201003, Val Accuracy: 0.7354596622889306\n",
      "Epoch 13/100, Loss: 0.37567835331856086, Val Accuracy: 0.7560975609756098\n",
      "Epoch 14/100, Loss: 0.3614028098989515, Val Accuracy: 0.7532833020637899\n",
      "Epoch 15/100, Loss: 0.3381744600302271, Val Accuracy: 0.7495309568480301\n",
      "Epoch 16/100, Loss: 0.30354738974950735, Val Accuracy: 0.7429643527204502\n",
      "Epoch 17/100, Loss: 0.27814310596565184, Val Accuracy: 0.7410881801125704\n",
      "Epoch 18/100, Loss: 0.2445261116219817, Val Accuracy: 0.7504690431519699\n",
      "Epoch 19/100, Loss: 0.22513658484995142, Val Accuracy: 0.7495309568480301\n",
      "Epoch 20/100, Loss: 0.19190874840882832, Val Accuracy: 0.7401500938086304\n",
      "Epoch 21/100, Loss: 0.18684630502671115, Val Accuracy: 0.7485928705440901\n",
      "Epoch 22/100, Loss: 0.14435458756034517, Val Accuracy: 0.7410881801125704\n",
      "Epoch 23/100, Loss: 0.11533595616266494, Val Accuracy: 0.7401500938086304\n",
      "Convergence reached, stopping training.\n",
      "Validation Accuracy: 0.7560975609756098, over 22 epochs\n"
     ]
    }
   ],
   "source": [
    "#Training the model with the best hyperparameters\n",
    "batch_size = 32\n",
    "lr=0.001\n",
    "model = RNNModel(embedding_matrix_array, hidden_size=128, output_size=1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_loader = create_data_loader(train_dataset_instance, batch_size)\n",
    "val_loader = create_data_loader(val_dataset_instance, batch_size)\n",
    "                \n",
    "# Train and validate\n",
    "val_acc, epochs_used = train_and_validate(model, train_loader, val_loader, optimizer, criterion)\n",
    "print(f\"Validation Accuracy: {val_acc}, over {epochs_used} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7326454033771107\n",
      "Final Configuration:\n",
      "Epochs: 22\n",
      "Learning Rate: 0.001\n",
      "Optimizer: Adam\n",
      "Batch Size: 32\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate on Test Set\n",
    "test_loader = create_data_loader(test_dataset_instance, batch_size)\n",
    "test_acc = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Report the configuration\n",
    "print(f\"Final Configuration:\\nEpochs: {epochs_used}\\nLearning Rate: {lr}\\nOptimizer: Adam\\nBatch Size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Sentence: 'directed in a flashy , empty sub-music video style by a director so self-possessed he actually adds a period to his first name'\n",
      "True Label: negative\n",
      "Predicted Label: negative\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Get a sample sentence from the test set and predict\n",
    "import random\n",
    "# Select a random index from the test dataset\n",
    "random_index = random.randint(0, len(test_dataset) - 1)\n",
    "\n",
    "# Get the corresponding sentence and its label from the test dataset\n",
    "sample_sentence = test_dataset[random_index]['text']  # Assuming the dataset contains a 'text' field\n",
    "true_label = test_dataset[random_index]['label']  # Assuming there's a label field\n",
    "\n",
    "# Tokenize the sample sentence\n",
    "sample_tokens = word_tokenize(sample_sentence.lower())\n",
    "\n",
    "# Convert tokens to indices\n",
    "sample_indices = []\n",
    "for token in sample_tokens:\n",
    "    if token in vocab:\n",
    "        sample_indices.append(list(vocab).index(token))\n",
    "    else:\n",
    "        sample_indices.append(list(vocab).index(\"<UNK>\"))\n",
    "sample_tensor = torch.tensor(sample_indices).unsqueeze(0)  # Add batch dimension\n",
    "# Make prediction using the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # No need to compute gradients during inference\n",
    "    output = model(sample_tensor)  # Pass the tensor to the model\n",
    "    _, predicted = torch.max(output, 1)  # Get the index of the max log-probability\n",
    "\n",
    "# Map predicted index to sentiment label\n",
    "sentiment_labels = ['negative', 'positive']  # Adjust according to your label encoding\n",
    "predicted_label = sentiment_labels[predicted.item()]\n",
    "\n",
    "# Print results\n",
    "print(f\"Sample Sentence: '{sample_sentence}'\")\n",
    "print(f\"True Label: {true_label}\")\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
