{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Downloading setuptools-75.2.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.0.5-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-17.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.10.10-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Collecting huggingface-hub>=0.22.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /Users/anushreearora/Library/Python/3.12/lib/python/site-packages (from datasets) (24.1)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.9.11-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.15.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2 (from requests>=2.32.2->datasets)\n",
      "  Downloading charset_normalizer-3.4.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/anushreearora/Library/Python/3.12/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/anushreearora/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets)\n",
      "  Downloading propcache-0.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Downloading torch-2.5.0-cp312-none-macosx_11_0_arm64.whl (64.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gensim-4.3.3-cp312-cp312-macosx_11_0_arm64.whl (24.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.10-cp312-cp312-macosx_11_0_arm64.whl (390 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.9/390.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.0-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp312-cp312-macosx_11_0_arm64.whl (27.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.3/173.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.7/284.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-macosx_12_0_arm64.whl (30.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.4/30.4 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.0.5-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-75.2.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.0-cp312-cp312-macosx_11_0_arm64.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.15.5-cp312-cp312-macosx_11_0_arm64.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading propcache-0.2.0-cp312-cp312-macosx_11_0_arm64.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, mpmath, xxhash, wrapt, urllib3, tzdata, typing-extensions, tqdm, sympy, setuptools, regex, pyyaml, propcache, numpy, networkx, multidict, MarkupSafe, joblib, idna, fsspec, frozenlist, filelock, dill, click, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, smart-open, scipy, requests, pyarrow, pandas, nltk, multiprocess, jinja2, aiosignal, torch, huggingface-hub, gensim, aiohttp, datasets\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 click-8.1.7 datasets-3.0.1 dill-0.3.8 filelock-3.16.1 frozenlist-1.4.1 fsspec-2024.6.1 gensim-4.3.3 huggingface-hub-0.26.0 idna-3.10 jinja2-3.1.4 joblib-1.4.2 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 networkx-3.4.1 nltk-3.9.1 numpy-1.26.4 pandas-2.2.3 propcache-0.2.0 pyarrow-17.0.0 pytz-2024.2 pyyaml-6.0.2 regex-2024.9.11 requests-2.32.3 scipy-1.13.1 setuptools-75.2.0 smart-open-7.0.5 sympy-1.13.1 torch-2.5.0 tqdm-4.66.5 typing-extensions-4.12.2 tzdata-2024.2 urllib3-2.2.3 wrapt-1.16.0 xxhash-3.5.0 yarl-1.15.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch gensim datasets nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "#nltk.download(\"all\")\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "\n",
    "from datasets import load_dataset\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = dataset['train'] \n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 8530 sentences\n",
      "Size of validation set: 1066 sentences\n",
      "Size of test set: 1066 sentences\n"
     ]
    }
   ],
   "source": [
    "#Number of sentences in each set \n",
    "print(f\"Size of training set: {train_dataset.num_rows} sentences\")\n",
    "print(f\"Size of validation set: {validation_dataset.num_rows} sentences\")\n",
    "print(f\"Size of test set: {test_dataset.num_rows} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence from train dataset: lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\n",
      "Label: Positive\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample sentence from train dataset: {test_dataset[0]['text']}\")\n",
    "print(f\"Label: {'Positive' if test_dataset[0]['label'] == 1 else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Preparing Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) What is the size of the vocabulary formed in your training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample sentence: ['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', \"'s\", 'new', '``', 'conan', '``', 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean-claud', 'van', 'damme', 'or', 'steven', 'segal', '.'] \n",
      "\n",
      "Number of words in the vocabulary(including padding and unknown tokens): 18031\n",
      "Number of words in the vocabulary: 18029\n"
     ]
    }
   ],
   "source": [
    "#tokenize sentences \n",
    "train_tokenized = []\n",
    "for sentence in train_dataset['text']:\n",
    "    train_tokenized.append(word_tokenize(sentence.lower()))\n",
    "\n",
    "print('sample sentence:', train_tokenized[0],'\\n')\n",
    "\n",
    "#build vocabulary\n",
    "vocab = {\"<PAD>\", \"<UNK>\"} #include a padding and unknown token for future processing\n",
    "vocab.update(word for sentence in train_tokenized for word in sentence)\n",
    "\n",
    "print(\"Number of words in the vocabulary(including padding and unknown tokens):\", len(vocab))\n",
    "print(\"Number of words in the vocabulary:\" , len(vocab)-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) We use OOV (out-of-vocabulary) to refer to those words appeared in the training data but not in the Word2vec (or Glove) dictionary. How many OOV words exist in your training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) The existence of the OOV words is one of the well-known limitations of Word2vec (or Glove). Without using any transformer-based language models (e.g., BERT, GPT, T5), what do you think is the best strategy to mitigate such limitation? Implement your solution in your source code. Show the corresponding code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OOV words with Word2Vec: 3612\n",
      "Embedding for <PAD>: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Embedding for <UNK>: [ 6.02571083e-03  1.81373160e-01 -3.16621778e-02 -1.36948329e-01\n",
      "  2.03860790e-01 -2.39361123e-01  7.84555506e-02 -1.96950804e-01\n",
      "  8.88372281e-02  8.54669976e-03  1.58139520e-01  8.64991581e-02\n",
      "  5.01998963e-02 -2.48910121e-01  8.61681199e-02 -6.22223526e-02\n",
      " -1.38642434e-02  7.93880217e-02 -8.23432175e-02 -8.60754403e-02\n",
      " -6.58178585e-02  1.51300033e-01 -1.71301078e-01 -2.05074575e-01\n",
      " -2.17082863e-01  1.71136479e-01 -4.03542688e-02  4.19674443e-02\n",
      " -1.90153614e-01  8.53896791e-02  1.96705610e-01 -4.02986203e-02\n",
      " -1.39858331e-01 -2.39110333e-01  2.20397693e-02  3.67171810e-02\n",
      " -1.56432884e-01 -5.61286148e-02  1.79400960e-01  1.98450918e-01\n",
      " -3.58577803e-03 -1.89852808e-01  4.85317844e-02  8.20921174e-02\n",
      "  1.83281541e-04  1.66624588e-01 -2.32015823e-01 -1.16731296e-01\n",
      " -4.25155064e-02  8.69045393e-02  1.12981316e-01  9.72246137e-02\n",
      " -1.36973280e-01 -3.81158406e-02 -3.29550164e-02 -6.71234496e-02\n",
      " -1.22078901e-01 -2.40684300e-01  2.21125007e-01  1.06482515e-01\n",
      " -2.49575748e-01 -1.99344375e-01  2.19815043e-01  5.80746038e-02\n",
      "  1.71998198e-01  1.35152744e-01  4.73484124e-02  1.93981953e-01\n",
      "  5.35779500e-02 -9.65276102e-02  2.46635898e-01  1.17232135e-01\n",
      " -1.77993539e-01 -8.88303645e-02  2.27939256e-02  8.10397400e-02\n",
      " -1.22541771e-01 -2.22688766e-01  1.95453820e-01 -1.64554567e-01\n",
      "  1.85575294e-01 -1.88675802e-02 -8.49893769e-02  2.49319093e-02\n",
      " -6.16289704e-02  2.08655762e-01 -4.08156413e-02 -2.41978133e-01\n",
      "  2.09976143e-01 -1.66790298e-01 -1.25828195e-01 -1.99766537e-01\n",
      " -1.93215551e-01  9.82862362e-02 -1.49155359e-01  4.64577499e-02\n",
      " -1.07267291e-01 -1.07878376e-01 -1.25300585e-01  4.99362152e-02\n",
      "  1.75905645e-02 -1.13471667e-01  1.11359031e-01  1.08078178e-02\n",
      " -2.49884589e-01 -1.17459092e-01  2.03686076e-01 -1.30022006e-01\n",
      " -2.29030844e-01 -8.01737186e-02 -2.24927911e-01  6.39615755e-02\n",
      " -1.68741271e-01 -6.49731127e-02 -1.31423463e-01  6.96302486e-02\n",
      "  2.06649518e-01  1.91872714e-01 -1.64497406e-01 -7.07529832e-03\n",
      "  2.36250534e-01  1.35741784e-01  1.29770900e-01  3.28394525e-02\n",
      "  2.04172870e-01 -1.40315030e-01 -5.24119261e-02  1.01420879e-01\n",
      "  2.04706451e-01 -2.48357783e-01  1.78553065e-01  1.47410173e-01\n",
      "  2.07509338e-02  1.97047952e-03  1.74600456e-01  4.18468146e-02\n",
      " -2.71668864e-02 -2.10222722e-01 -3.47167411e-02 -1.20787147e-02\n",
      " -1.90703597e-01  1.70690023e-01 -2.34101846e-01  6.12337520e-02\n",
      " -2.43244429e-01 -1.77076877e-01 -2.43804498e-01 -2.31384219e-01\n",
      "  2.15246004e-01  3.63650398e-02 -1.42607573e-01 -1.81465088e-01\n",
      "  1.00310164e-01  6.49107626e-02  2.04490319e-01  5.23241940e-02\n",
      " -5.16101128e-02  2.22572995e-01 -2.37530120e-01  1.14551386e-01\n",
      "  7.23343879e-02  3.67694774e-02  1.56406802e-01  1.56295137e-01\n",
      "  3.39683980e-02  6.88573609e-02 -4.18199396e-02 -2.34285021e-01\n",
      " -6.00368559e-02 -2.09318822e-01 -2.85831536e-02 -7.47914535e-02\n",
      " -2.03833025e-01  6.05143080e-02  4.07379950e-02 -1.28544731e-01\n",
      " -5.57894959e-02 -1.45985513e-01 -2.32758120e-01 -1.07681485e-01\n",
      " -3.58250650e-02 -5.37848857e-02  2.06186548e-01 -2.47668409e-01\n",
      "  1.42143737e-01  7.71718519e-02  8.23002158e-03  1.77096033e-01\n",
      "  2.94684313e-02  4.64678358e-02 -1.88976160e-01 -1.14333946e-01\n",
      " -1.51483020e-01  2.20787892e-01  1.18486592e-02 -1.30510210e-01\n",
      "  9.91912446e-02  1.19529092e-01 -1.36236863e-02  4.16628217e-02\n",
      "  1.50142806e-01  2.00560828e-01 -1.73947838e-02 -1.64760606e-02\n",
      " -1.25853494e-01 -2.45448941e-01 -7.67379342e-02  1.96714666e-01\n",
      " -2.15318582e-03 -2.17353386e-01  1.14333756e-01  1.24793237e-01\n",
      " -8.85649491e-02 -5.74270903e-02  5.02800362e-02  1.09548657e-01\n",
      "  7.15900973e-02 -1.68065983e-01 -8.95873865e-02  1.78594222e-01\n",
      " -4.11852141e-02 -2.15503923e-02  6.74191863e-02  1.81636401e-01\n",
      "  1.37805703e-01 -2.97056071e-02  1.94221493e-01 -1.78915366e-01\n",
      "  9.26308525e-02  1.02782867e-01 -2.34095820e-01 -1.69441798e-01\n",
      "  8.63751608e-02 -1.65181695e-01 -1.84055262e-01  7.98790346e-02\n",
      " -1.06731283e-01 -3.14329439e-02  7.30610234e-03  1.45462988e-01\n",
      "  9.94443747e-02 -1.33779912e-01 -9.58101222e-02  2.01502697e-01\n",
      "  3.73873431e-02  2.01056042e-01 -2.11317380e-01  5.14628196e-03\n",
      " -7.33655767e-02 -2.21752783e-01  3.08646601e-02  9.12700035e-02\n",
      "  1.03606125e-01  1.89426176e-01  2.18314965e-01 -2.36833178e-01\n",
      "  5.12440484e-03 -1.54645993e-01 -1.00982773e-01 -4.83058128e-02\n",
      "  2.13951999e-01  2.12112883e-01 -2.20018204e-01  4.47579947e-02\n",
      " -1.63563316e-01  1.49005823e-01  2.03980405e-01  1.57153550e-01\n",
      " -1.20881345e-01  2.85012787e-02  9.60854103e-02  1.10363274e-01\n",
      " -1.43679175e-01  2.56834007e-02  2.26232074e-01  4.27285671e-02\n",
      " -8.56381953e-02 -1.89607562e-01 -2.19492698e-01 -4.07042550e-02\n",
      " -1.53375325e-01 -1.83175287e-01  5.59903227e-02 -2.28182869e-01\n",
      "  3.28966869e-02 -2.21645753e-01 -1.52660476e-01  2.37662257e-01\n",
      " -2.01018566e-01  2.23569862e-01 -7.64693890e-02  1.36601045e-01\n",
      "  1.37535317e-01  2.22728482e-01  1.45152022e-01 -8.87158831e-02\n",
      " -2.12186184e-01  8.80236331e-02  2.26369106e-01  2.30819820e-01]\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained Word2Vec model (Google News Word2Vec)\n",
    "word2vec = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Set embedding size\n",
    "embedding_size = 300\n",
    "\n",
    "# Initialize the embedding matrix with zeros for padding and random values for unknown tokens\n",
    "embedding_matrix = {}\n",
    "\n",
    "# Create an <UNK> token embedding as a random vector\n",
    "unk_vector = np.random.uniform(-0.25, 0.25, embedding_size)\n",
    "embedding_matrix[\"<UNK>\"] = unk_vector\n",
    "\n",
    "# Create a <PAD> token embedding as a zero vector\n",
    "pad_vector = np.zeros(embedding_size)\n",
    "embedding_matrix[\"<PAD>\"] = pad_vector\n",
    "\n",
    "# Initialize OOV counter\n",
    "oov_count = 0\n",
    "\n",
    "# Iterate over the vocabulary\n",
    "for word in vocab:\n",
    "    if word == \"<PAD>\" or word == \"<UNK>\":\n",
    "        continue  \n",
    "    \n",
    "    if word in word2vec:  # If the word is in Word2Vec, add its embedding\n",
    "        embedding_matrix[word] = word2vec[word]\n",
    "    else:\n",
    "        # If the word is OOV, assign it the <UNK> vector and count as OOV\n",
    "        embedding_matrix[word] = unk_vector  # Assign OOV words the <UNK> vector\n",
    "        oov_count += 1  # Increment OOV counter\n",
    "\n",
    "# Print results for Word2Vec\n",
    "print(f\"Number of OOV words with Word2Vec: {oov_count}\")\n",
    "print(f\"Embedding for <PAD>: {embedding_matrix['<PAD>']}\")\n",
    "print(f\"Embedding for <UNK>: {embedding_matrix['<UNK>']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OOV words with FastText: 1961\n",
      "Embedding for <PAD>: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Embedding for <UNK>: [ 0.08061819 -0.05043139 -0.1693268   0.14913988  0.24657828 -0.06309615\n",
      " -0.10062838  0.19911319 -0.2497434   0.21925435  0.07451584  0.10453782\n",
      "  0.17615385 -0.21532285 -0.19896437  0.21272083 -0.1673301  -0.10383954\n",
      "  0.10194353  0.09644451 -0.18535964 -0.15422637  0.0267945   0.06567047\n",
      " -0.10187319  0.09905686  0.24355783 -0.04265137  0.23320612  0.0934664\n",
      "  0.06175258 -0.14091197  0.00919645 -0.04117995  0.07852519 -0.13704929\n",
      " -0.04205589  0.05059972  0.08581146 -0.0493695   0.16308716  0.08895734\n",
      "  0.18121798  0.08844517 -0.18124143 -0.1267732   0.17602138  0.09106957\n",
      "  0.1155959  -0.16704947 -0.02634222 -0.01233913  0.02272745 -0.12696423\n",
      "  0.19451869  0.08394463 -0.05925377  0.03614557  0.11137182 -0.01361394\n",
      "  0.23651874  0.01396621 -0.10276983 -0.0525151  -0.12199785 -0.19288962\n",
      "  0.18142941 -0.15122242 -0.0128728   0.13495854  0.23272845  0.02768905\n",
      "  0.03833313  0.22257288  0.21418305  0.17769797 -0.11395428  0.01158805\n",
      "  0.01217908 -0.20848104  0.14953629  0.13699255  0.14430199 -0.17272121\n",
      "  0.02706397 -0.14540273 -0.00030298 -0.07255976  0.06792285 -0.16549632\n",
      "  0.19405685  0.19744469 -0.00814338  0.17308284 -0.11763669  0.05000181\n",
      " -0.21704829 -0.24537654  0.02496531  0.13204708 -0.1536067   0.09794607\n",
      " -0.14702028  0.2395745  -0.22410793 -0.09444824  0.24866776 -0.04606885\n",
      " -0.06802254  0.07273459 -0.06075641  0.10055391  0.13814939 -0.04501941\n",
      " -0.1300328  -0.01438856 -0.18523312 -0.23464455  0.22990799 -0.12631377\n",
      " -0.20734604  0.24099789 -0.0405852  -0.06427463 -0.16132373  0.0902499\n",
      "  0.15897202  0.09387255  0.02036854 -0.20203023  0.11786816  0.05287637\n",
      " -0.14837239 -0.11148643  0.04473623  0.07136546  0.19287213 -0.23892502\n",
      "  0.23207296  0.09036293 -0.03964886  0.12253145  0.23090655  0.06849469\n",
      " -0.0360211  -0.04867264  0.11638187  0.15064928 -0.00411122 -0.16869425\n",
      "  0.17692689  0.0723101  -0.06624882 -0.18362612 -0.16462868  0.2350168\n",
      "  0.18997546  0.17933661 -0.14511149 -0.1976848  -0.01009414 -0.20463169\n",
      "  0.14037467 -0.11925918 -0.16010309 -0.02889303 -0.01596078 -0.00083321\n",
      "  0.07511222  0.1359442   0.14303622  0.1432019   0.18299215 -0.07696144\n",
      "  0.12034087  0.22802942 -0.13876537  0.06901739 -0.19260761  0.04417118\n",
      "  0.21913022  0.16254913  0.14177471  0.03211577  0.12840513  0.17421176\n",
      " -0.01715595  0.15101653  0.2437818  -0.07163575  0.20988961 -0.06594184\n",
      " -0.10756504  0.00745057 -0.19085379 -0.2236202   0.22019347  0.11008271\n",
      " -0.14145656  0.1171984   0.0155462  -0.1905227   0.11564325 -0.08499262\n",
      " -0.18734213  0.21914928  0.24288035 -0.24841311 -0.00312843 -0.13221025\n",
      "  0.21485046 -0.00412553 -0.22139876  0.0389855   0.07887597 -0.08895396\n",
      " -0.04532037 -0.17222601 -0.19483558  0.14685934  0.24007213  0.22850425\n",
      "  0.22957005 -0.12196674 -0.12174041  0.24948301  0.09562058  0.24025689\n",
      " -0.2365147  -0.03764751  0.05998672  0.1382815  -0.10345761 -0.17111387\n",
      "  0.12565725 -0.00147018  0.03880225  0.00205863  0.14619103 -0.12481326\n",
      " -0.0525728   0.22752365 -0.07215822 -0.18489696  0.24294004 -0.24599112\n",
      "  0.03020887 -0.09634075  0.13564702  0.1192752   0.12687669  0.22642836\n",
      "  0.01293053 -0.0226764   0.13906406  0.16117032 -0.11056671  0.08098681\n",
      " -0.23580596  0.08187579  0.16402847  0.12951818  0.12629597  0.09792628\n",
      " -0.04871237 -0.21242955 -0.19397349 -0.02664194 -0.03813336 -0.1094093\n",
      "  0.03317977 -0.12868109  0.00583139 -0.01783665  0.11158971 -0.20805701\n",
      "  0.16935531 -0.18070409  0.22050283 -0.07461019 -0.02557423 -0.13543275\n",
      " -0.03283006  0.02082717  0.18388517 -0.02421537  0.117144   -0.18775702\n",
      " -0.02255105 -0.12821173  0.2376743   0.1713721  -0.11369296 -0.19736716\n",
      "  0.22912053 -0.17640367 -0.05357447  0.1625283   0.17467525  0.21323695]\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained FastText model (wiki-news-300d-subword)\n",
    "fasttext_model = api.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "# Set embedding size\n",
    "embedding_size = 300\n",
    "\n",
    "# Initialize the embedding matrix with zeros for padding and random values for unknown tokens\n",
    "embedding_matrix = {}\n",
    "\n",
    "# Create an <UNK> token embedding as a random vector\n",
    "unk_vector = np.random.uniform(-0.25, 0.25, embedding_size)\n",
    "embedding_matrix[\"<UNK>\"] = unk_vector\n",
    "\n",
    "# Create a <PAD> token embedding as a zero vector\n",
    "pad_vector = np.zeros(embedding_size)\n",
    "embedding_matrix[\"<PAD>\"] = pad_vector\n",
    "\n",
    "# Initialize OOV counter for FastText\n",
    "oov_count_fasttext = 0\n",
    "\n",
    "# Iterate over the vocabulary\n",
    "for word in vocab:\n",
    "    if word == \"<PAD>\" or word == \"<UNK>\":\n",
    "        continue  \n",
    "    \n",
    "    try:\n",
    "        # Try to get the word vector using FastText's subword handling\n",
    "        embedding_matrix[word] = fasttext_model.get_vector(word)\n",
    "    except KeyError:\n",
    "        # If the word can't be processed even by FastText, assign it the <UNK> vector\n",
    "        embedding_matrix[word] = unk_vector\n",
    "        oov_count_fasttext += 1  # Increment OOV count\n",
    "\n",
    "# Print results for FastText\n",
    "print(f\"Number of OOV words with FastText: {oov_count_fasttext}\")\n",
    "print(f\"Embedding for <PAD>: {embedding_matrix['<PAD>']}\")\n",
    "print(f\"Embedding for <UNK>: {embedding_matrix['<UNK>']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
