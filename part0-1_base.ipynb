{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "import spacy as spacy\n",
    "\n",
    "from datasets import load_dataset\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = dataset['train'] \n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 8530 sentences\n",
      "Size of validation set: 1066 sentences\n",
      "Size of test set: 1066 sentences\n"
     ]
    }
   ],
   "source": [
    "#Number of sentences in each set \n",
    "print(f\"Size of training set: {train_dataset.num_rows} sentences\")\n",
    "print(f\"Size of validation set: {validation_dataset.num_rows} sentences\")\n",
    "print(f\"Size of test set: {test_dataset.num_rows} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence from train dataset: lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\n",
      "Label: Positive\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample sentence from train dataset: {test_dataset[0]['text']}\")\n",
    "print(f\"Label: {'Positive' if test_dataset[0]['label'] == 1 else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the vocabulary: 16631\n",
      "Sample tokenized sentence: ['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', \"'s\", 'new', '\"', 'conan', '\"', 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean', '-', 'claud', 'van', 'damme', 'or', 'steven', 'segal', '.']\n"
     ]
    }
   ],
   "source": [
    "# Load SpaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def build_vocab(train_dataset):\n",
    "    vocab = set()\n",
    "    train_tokenized = []  # Store tokenized sentences\n",
    "\n",
    "    # Loop through each sentence in the dataset\n",
    "    for sentence in train_dataset['text']:\n",
    "        # Use SpaCy's tokenizer\n",
    "        doc = nlp(sentence.lower())  # Lowercase for consistency\n",
    "\n",
    "        # Extract tokens\n",
    "        word_list = [token.text for token in doc]  # Tokenized words\n",
    "\n",
    "        # Add cleaned words into the vocabulary (no need to strip quotes with SpaCy)\n",
    "        vocab.update(word_list)\n",
    "\n",
    "        # Store tokenized sentence\n",
    "        train_tokenized.append(word_list)\n",
    "\n",
    "    vocab.discard('')  # Remove any empty string from the vocabulary\n",
    "    \n",
    "    # Convert vocab set to a list to index it\n",
    "    vocab_list = sorted(vocab)\n",
    "    return vocab, train_tokenized\n",
    "\n",
    "vocab_list, train_tokenized = build_vocab(train_dataset)\n",
    "\n",
    "# Show the number of words in the vocabulary\n",
    "print(f\"Number of words in the vocabulary: {len(vocab_list)}\")\n",
    "\n",
    "# Print a sample tokenized sentence\n",
    "print(\"Sample tokenized sentence:\", train_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word-to-index mapping: [('<PAD>', 0), ('<UNK>', 1), ('fortunately', 2), ('aussie', 3), ('rap', 4), ('attempt', 5), ('iben', 6), ('research', 7), ('struggles', 8), ('getting', 9)]\n"
     ]
    }
   ],
   "source": [
    "# Initialize word_to_index with <PAD> at 0 and <UNK> at 1\n",
    "word_to_index = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "\n",
    "# Assign indices to words in vocab_list starting from 2\n",
    "for idx, word in enumerate(vocab_list, start=2):\n",
    "    word_to_index[word] = idx\n",
    "\n",
    "print(\"Sample word-to-index mapping:\", list(word_to_index.items())[:10])  # Display first 10 mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(file_path, embedding_size=300):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            if len(vector) == embedding_size:\n",
    "                embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "# Path to GloVe embeddings file and embedding size\n",
    "glove_path = '/Users/anushreearora/Downloads/glove/glove.6B.300d.txt'  \n",
    "embedding_size = 300\n",
    "glove_embeddings = load_glove_embeddings(glove_path, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embedding matrix with None values for all words\n",
    "embedding_matrix = [None] * (len(vocab_list) + 2)  # +2 for <PAD> and <UNK> tokens\n",
    "\n",
    "# Define <UNK> and <PAD> embeddings\n",
    "unk_vector = np.random.uniform(-0.25, 0.25, embedding_size)  # Random vector for <UNK>\n",
    "pad_vector = np.zeros(embedding_size)  # Zero vector for <PAD>\n",
    "\n",
    "# Set <PAD> and <UNK> embeddings initially\n",
    "embedding_matrix[0] = pad_vector  # <PAD> at index 0\n",
    "embedding_matrix[1] = unk_vector  # <UNK> at index 1\n",
    "\n",
    "# Populate the embedding matrix\n",
    "for word, idx in word_to_index.items():\n",
    "    if word in glove_embeddings:\n",
    "        embedding_matrix[idx] = glove_embeddings[word]  # Assign GloVe embedding\n",
    "    # If the word is not in GloVe, it remains None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OOV words: 690\n",
      "--with\n",
      "-a\n",
      "-after\n",
      "-doing\n",
      "-greaseballs\n",
      "-hollywood\n",
      "-inevitable\n",
      "-of\n",
      "-quite\n",
      "-stunning\n",
      "-the\n",
      "-west\n",
      "28k\n",
      "3/4th\n",
      "4/5ths\n",
      "a]n\n",
      "abandone\n",
      "aborbing\n",
      "absolutamente\n",
      "aburrido\n",
      "acabamos\n",
      "accomodates\n",
      "aceitou\n",
      "achival\n",
      "achronological\n",
      "acontecimentos\n",
      "actorish\n",
      "actory\n",
      "actuación\n",
      "actuada\n",
      "adapted-\n",
      "addessi\n",
      "adorability\n",
      "adventues\n",
      "affirmational\n",
      "ain't-\n",
      "alientation\n",
      "allodi\n",
      "amoses\n",
      "amusedly\n",
      "and-\n",
      "andamento\n",
      "animé\n",
      "anteing\n",
      "apallingly\n",
      "apesar\n",
      "aproveitar\n",
      "aqueles\n",
      "aren't\n",
      "arriesgado\n",
      "artsploitation\n",
      "artístico\n",
      "assistir\n",
      "atacar\n",
      "atacarse\n",
      "atreve\n",
      "auteil\n",
      "autocritique\n",
      "b+\n",
      "bazadona\n",
      "bergmanesque\n",
      "beseechingly\n",
      "bibbidy\n",
      "bierbichler\n",
      "birot\n",
      "bizzarre\n",
      "bjorkness\n",
      "black-&-white\n",
      "blighter\n",
      "blutarsky\n",
      "bobbidi\n",
      "bondish\n",
      "bornin\n",
      "bottomlessly\n",
      "bruckheimeresque\n",
      "brûlée\n",
      "bull's\n",
      "burningly\n",
      "bustingly\n",
      "butterfingered\n",
      "c'm\n",
      "cadness\n",
      "cam'ron\n",
      "camareras\n",
      "can&#8217\n",
      "cannier\n",
      "captivatingly\n",
      "capturou\n",
      "carente\n",
      "cativante\n",
      "catsup--\n",
      "certamente\n",
      "chabrolian\n",
      "character-\n",
      "character]is\n",
      "chopsocky\n",
      "choquart\n",
      "cineasts\n",
      "cinemantic\n",
      "cipherlike\n",
      "cirulnick\n",
      "class-\n",
      "claustrophic\n",
      "clericks\n",
      "cletis\n",
      "clichês\n",
      "clutchy\n",
      "collosum\n",
      "colocar\n",
      "colonics\n",
      "colosal\n",
      "começamos\n",
      "compleja\n",
      "complejos\n",
      "complementares\n",
      "condensada\n",
      "conmovedora\n",
      "consegue\n",
      "constatação\n",
      "contando\n",
      "contemplarse\n",
      "continuação\n",
      "contructed\n",
      "contrária\n",
      "convencional\n",
      "copmovieland\n",
      "coriat\n",
      "corniest\n",
      "corruscating\n",
      "costumey\n",
      "covardia\n",
      "crappola\n",
      "criar\n",
      "crowdpleaser\n",
      "crummles\n",
      "culminando\n",
      "d]espite\n",
      "d]oesn't\n",
      "daneses\n",
      "datedness\n",
      "dateflick\n",
      "deadeningly\n",
      "debuter\n",
      "decasia\n",
      "decidiram\n",
      "decirles\n",
      "defeatingly\n",
      "delibrately\n",
      "delicia\n",
      "demencial\n",
      "democracie\n",
      "denlopp\n",
      "derivativeness\n",
      "desaponta\n",
      "desarrollarse\n",
      "desee\n",
      "deseos\n",
      "desfecho\n",
      "desnudo\n",
      "destinees\n",
      "deutchland\n",
      "diciness\n",
      "diferença\n",
      "digno\n",
      "direto\n",
      "diretor\n",
      "direção\n",
      "disfrutable\n",
      "disposible\n",
      "divertida\n",
      "divertingly\n",
      "djeinaba\n",
      "dogwalker\n",
      "dominatrixes\n",
      "don't\n",
      "dooper\n",
      "double-\n",
      "dreadfulness\n",
      "drek\n",
      "dridi\n",
      "drippiness\n",
      "dudsville\n",
      "dullingly\n",
      "dumbfoundingly\n",
      "duración\n",
      "dysfunctionally\n",
      "dès\n",
      "e]ventually\n",
      "early-'80s\n",
      "efteriades\n",
      "elegiacally\n",
      "elemento\n",
      "else-\n",
      "emocionalmente\n",
      "emocionante\n",
      "emotiva\n",
      "emptily\n",
      "enfrentados\n",
      "enfrentará\n",
      "engaña\n",
      "enrapturing\n",
      "enternecedora\n",
      "entretenida\n",
      "entreter\n",
      "entretiene\n",
      "então\n",
      "enviará\n",
      "episódio\n",
      "equlibrium\n",
      "eroti\n",
      "escapa\n",
      "esfera\n",
      "esforço\n",
      "espectáculo\n",
      "espetáculo\n",
      "esquerdo\n",
      "estafeta\n",
      "estava\n",
      "esteticamente\n",
      "estranhos\n",
      "estudo\n",
      "estupendamente\n",
      "everlyn\n",
      "evolução\n",
      "excrescence\n",
      "exhilarate\n",
      "exibi\n",
      "existência\n",
      "explicados\n",
      "exporing\n",
      "expresar\n",
      "f]rom\n",
      "fantasti\n",
      "fascinantes\n",
      "fato\n",
      "feardotcom\n",
      "felinni\n",
      "fillm\n",
      "fizzability\n",
      "flakeball\n",
      "flatula\n",
      "flck\n",
      "fluxing\n",
      "forgettably\n",
      "four-\n",
      "francamente\n",
      "frissons\n",
      "frustrado\n",
      "fuddled\n",
      "fuhgeddaboutit\n",
      "fun's\n",
      "funcionar\n",
      "fustily\n",
      "fílmica\n",
      "gabbiest\n",
      "ganha\n",
      "gantzes\n",
      "gasm\n",
      "gaï\n",
      "gerbosi\n",
      "girl-\n",
      "glizty\n",
      "gooeyness\n",
      "goombah\n",
      "gorefests\n",
      "gosto\n",
      "government/\n",
      "grandiosa\n",
      "grato\n",
      "graças\n",
      "greasiest\n",
      "guessable\n",
      "guión\n",
      "gutterball\n",
      "gymkata\n",
      "h]ad\n",
      "halfwit\n",
      "hamfisted\n",
      "hammily\n",
      "haphazardness\n",
      "hard-\n",
      "hastier\n",
      "havia\n",
      "headbangingly\n",
      "heartwarmingly\n",
      "heidegger-\n",
      "hellstenius\n",
      "heremakono\n",
      "higuchinsky\n",
      "hirosue\n",
      "histo\n",
      "hit-\n",
      "hitchcockianism\n",
      "hjelje\n",
      "hobnail\n",
      "hopkins]doesn't\n",
      "hotdogging\n",
      "hotsies\n",
      "hubac\n",
      "humbuggery\n",
      "i'm\n",
      "i]f\n",
      "i]t\n",
      "idemoto\n",
      "idoosyncratic\n",
      "igualmente\n",
      "ihops\n",
      "ii--\n",
      "imaginación\n",
      "imponderably\n",
      "impotentes\n",
      "in-\n",
      "incoloro\n",
      "incompetência\n",
      "inconsequentiality\n",
      "indieflick\n",
      "inducingly\n",
      "inept-\n",
      "ineptitudes\n",
      "inhospitability\n",
      "inquestionável\n",
      "instante\n",
      "intacto\n",
      "intelectualmente\n",
      "intentando\n",
      "interações\n",
      "interspliced\n",
      "involvingly\n",
      "início\n",
      "it's\n",
      "italianas\n",
      "italicizes\n",
      "jaglomized\n",
      "janklowicz\n",
      "japanimator\n",
      "jealousy-\n",
      "jirí\n",
      "joylessly\n",
      "juiceless\n",
      "kahlories\n",
      "kalesniko\n",
      "kalvert\n",
      "kaputschnik\n",
      "kazmierski\n",
      "keep-'em\n",
      "kibbitzes\n",
      "kickass\n",
      "kidlets\n",
      "kilmer&#8217\n",
      "komediant\n",
      "kosashvili\n",
      "koshashvili\n",
      "l]ame\n",
      "laboriousness\n",
      "landbound\n",
      "lapdance\n",
      "leatherbound\n",
      "leplouff\n",
      "less-\n",
      "lhe\n",
      "likableness\n",
      "logra\n",
      "low-\n",
      "luvvies\n",
      "lástima\n",
      "líquido\n",
      "maelström\n",
      "major-\n",
      "makmalbaf\n",
      "manipulador\n",
      "manqué\n",
      "marcken\n",
      "margolo\n",
      "marveilleux\n",
      "masterpeice\n",
      "materalism\n",
      "matrix'-style\n",
      "mcklusky\n",
      "meaningness\n",
      "meanspirited\n",
      "mediocridade\n",
      "melodic/\n",
      "melodramáticos\n",
      "memória\n",
      "mergulha\n",
      "mesmos\n",
      "mibii\n",
      "mid-'70s\n",
      "mid-'90s\n",
      "miedos\n",
      "minac\n",
      "miscasts\n",
      "mollà\n",
      "monkeyfun\n",
      "montaje\n",
      "montias\n",
      "montied\n",
      "mouglalis\n",
      "movie--\n",
      "movieif\n",
      "movilizador\n",
      "mullinski\n",
      "musclefest\n",
      "musicais\n",
      "n]o\n",
      "narcotized\n",
      "narcotizing\n",
      "narrativa\n",
      "naturedness\n",
      "nebrida\n",
      "necessidade\n",
      "nerfs\n",
      "newton]wanders\n",
      "ninguém\n",
      "ningún\n",
      "nohe\n",
      "nolden\n",
      "nonchallenging\n",
      "nonethnic\n",
      "nutjob\n",
      "nuttgens\n",
      "næs\n",
      "obligada\n",
      "obviation\n",
      "of-\n",
      "off-\n",
      "on-\n",
      "ooky\n",
      "originalidad\n",
      "orquídeas\n",
      "ourside\n",
      "outgag\n",
      "outré\n",
      "over-25s\n",
      "overemphatic\n",
      "overmanipulative\n",
      "overplotted\n",
      "overstylized\n",
      "ozpetek\n",
      "oídos\n",
      "p]artnering\n",
      "papai\n",
      "paródia\n",
      "patriotero\n",
      "penotti\n",
      "perde\n",
      "perdona\n",
      "perfervid\n",
      "perseguição\n",
      "personagens\n",
      "petin\n",
      "phonce\n",
      "pianista\n",
      "pincel\n",
      "pistoled\n",
      "plaintiveness\n",
      "pokepie\n",
      "policiales\n",
      "pollyana\n",
      "possui\n",
      "post-9/11\n",
      "pouquíssimos\n",
      "powaqqatsi\n",
      "prechewed\n",
      "preciosista\n",
      "precisa\n",
      "precollegiate\n",
      "predecesora\n",
      "predecible\n",
      "prefeminist\n",
      "prejuicios\n",
      "premisa\n",
      "premissa\n",
      "preocupar\n",
      "preocupe\n",
      "prescinde\n",
      "pretenciosas\n",
      "pretention\n",
      "prewarned\n",
      "profundamente\n",
      "projeção\n",
      "provide[s\n",
      "provocatuers\n",
      "próprio\n",
      "psychodramatics\n",
      "pulpiness\n",
      "puportedly\n",
      "puréed\n",
      "put[s\n",
      "puttingly\n",
      "pérdida\n",
      "péssima\n",
      "qatsi\n",
      "quizá\n",
      "qutting\n",
      "rambo-\n",
      "re-\n",
      "realidade\n",
      "realshe\n",
      "recoing\n",
      "reconceptualize\n",
      "recurre\n",
      "reeboir\n",
      "reeses\n",
      "repellantly\n",
      "representando\n",
      "repulsively\n",
      "responsável\n",
      "resultan\n",
      "retadora\n",
      "retrata\n",
      "revigorates\n",
      "ricture\n",
      "rintarô\n",
      "roisterous\n",
      "romething\n",
      "románticas\n",
      "roteirista\n",
      "roteiro\n",
      "runteldat\n",
      "russos\n",
      "ryanovich\n",
      "rápidamente\n",
      "s1m0ne\n",
      "sailboaters\n",
      "sake-\n",
      "salaciously\n",
      "sandlerian\n",
      "sappier\n",
      "sarcástica\n",
      "satirizado\n",
      "saído\n",
      "saímos\n",
      "schneidermeister\n",
      "scuzbag\n",
      "seldahl\n",
      "self-\n",
      "sequer\n",
      "sermonize\n",
      "shagster\n",
      "shakesperean\n",
      "shall-\n",
      "shapable\n",
      "shapelessly\n",
      "shayamalan\n",
      "sheerly\n",
      "shimmeringly\n",
      "shlockmeister\n",
      "shmear\n",
      "shoot-'em\n",
      "shoplifts\n",
      "shrieky\n",
      "silbersteins\n",
      "sillified\n",
      "simbolizando\n",
      "sinais\n",
      "sincera\n",
      "sitcomishly\n",
      "siuation\n",
      "skeeved\n",
      "skippable\n",
      "slappingly\n",
      "slowtime\n",
      "slummy\n",
      "smashups\n",
      "snazziness\n",
      "snoots\n",
      "soaringly\n",
      "soberbio\n",
      "sogginess\n",
      "solondzian\n",
      "sorprenderá\n",
      "soul's\n",
      "sparklingly\n",
      "speeds/\n",
      "splatterfests\n",
      "splittingly\n",
      "spookies\n",
      "squaddie\n",
      "stagecrafts\n",
      "stalk'n'slash\n",
      "steinis\n",
      "stoppingly\n",
      "stortelling\n",
      "strafings\n",
      "strainingly\n",
      "stuffiest\n",
      "stultifyingly\n",
      "stumblings\n",
      "stuporously\n",
      "substitutable\n",
      "sumamente\n",
      "super-\n",
      "superada\n",
      "superficiale\n",
      "superlarge\n",
      "surehanded\n",
      "surfacey\n",
      "suspeito\n",
      "suspenser\n",
      "swordfights\n",
      "sychowski\n",
      "sytle\n",
      "t&a\n",
      "t]he\n",
      "t]here\n",
      "t]his\n",
      "t]hose\n",
      "t]oo\n",
      "talancón\n",
      "também\n",
      "tardier\n",
      "television-\n",
      "the-\n",
      "thekids\n",
      "thesps\n",
      "thons\n",
      "timewaster\n",
      "toolbags\n",
      "transfigures\n",
      "transforma\n",
      "travil\n",
      "truncheoning\n",
      "término\n",
      "têm\n",
      "u]nrelentingly\n",
      "uberviolence\n",
      "unamusing\n",
      "uncharismatically\n",
      "uncinematic\n",
      "unclassifiably\n",
      "unconned\n",
      "underdramatized\n",
      "unembarrassing\n",
      "unemotive\n",
      "unencouraging\n",
      "unentertaining\n",
      "unfakable\n",
      "unforgivingly\n",
      "unhibited\n",
      "unimpressively\n",
      "universos\n",
      "unlaughable\n",
      "unplundered\n",
      "unrecommendable\n",
      "unreligious\n",
      "unsalvageability\n",
      "unslick\n",
      "unsuspenseful\n",
      "untugged\n",
      "updatings\n",
      "uplifter\n",
      "utilizar\n",
      "verete\n",
      "versión\n",
      "vidgame\n",
      "villians\n",
      "visualmente\n",
      "volletta\n",
      "vulakoro\n",
      "w]hile\n",
      "wankery\n",
      "watstein\n",
      "waydowntown\n",
      "weirded-\n",
      "wewannour\n",
      "what-\n",
      "whimsicality\n",
      "wifty\n",
      "wisegirls\n",
      "witch-\n",
      "witlessness\n",
      "wollter\n",
      "woman-\n",
      "world-\n",
      "years/\n",
      "zillionth\n",
      "zzzzzzzzz\n",
      "\n",
      " \n",
      "70s\n",
      "direct\n",
      "what\n",
      "\n",
      "\n",
      "às\n",
      "ápice\n",
      "ótimo\n",
      "últimos\n",
      "única\n"
     ]
    }
   ],
   "source": [
    "# Derive OOV words from the embedding matrix\n",
    "oov_words = [word for word, idx in word_to_index.items() if embedding_matrix[idx] is None]\n",
    "\n",
    "oov_words = sorted(oov_words)\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of OOV words: {len(oov_words)}\")\n",
    "for word in oov_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the <UNK> embedding to OOV words\n",
    "for word in oov_words:\n",
    "    idx = word_to_index[word]\n",
    "    embedding_matrix[idx] = unk_vector  # Assign <UNK> vector to OOV words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the embedding matrix to a NumPy array\n",
    "embedding_matrix_np = np.array(embedding_matrix)\n",
    "\n",
    "# Save both the embedding matrix and word_to_index mapping as a pickle file\n",
    "with open(\"base_embedding_matrix.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"embeddings\": embedding_matrix_np, \"word_to_index\": word_to_index}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
